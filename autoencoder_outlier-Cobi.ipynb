{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=\"cobi_state_data.csv\"\n",
    "df=pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsspeedmax=10.\n",
    "userPowermax=100.\n",
    "ridingDurationmax=500.\n",
    "ridingDistancemax=2000.\n",
    "ascentmax=15.\n",
    "caloriesmax=50.\n",
    "heartratemax=150.\n",
    "cadencemax=90.\n",
    "averageSpeedmax=8.\n",
    "\n",
    "df['rsspeed']=df['rsspeed']/rsspeedmax\n",
    "df['userPower']=df['userPower']/userPowermax\n",
    "df['ridingDuration']=df['ridingDuration']/ridingDurationmax\n",
    "df['ridingDistance']=df['ridingDistance']/ridingDistancemax\n",
    "df['ascent']=df['ascent']/ascentmax\n",
    "df['calories']=df['calories']/caloriesmax\n",
    "df['heartRate']=df['heartRate']/heartratemax\n",
    "df['cadence']=df['cadence']/cadencemax\n",
    "df['averageSpeed']=df['averageSpeed']/averageSpeedmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rsspeed',\n",
       " 'userPower',\n",
       " 'ridingDuration',\n",
       " 'ridingDistance',\n",
       " 'ascent',\n",
       " 'calories',\n",
       " 'heartRate',\n",
       " 'cadence',\n",
       " 'averageSpeed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[col for col in df.columns ]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dftrain,dftest=train_test_split(df,test_size=0.15)\n",
    "dftest['Class']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numinps= len(cols)\n",
    "numinps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Test/Train split for train and eval data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain2,dfeval=train_test_split(dftrain,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Building the autoencoder</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So the Threshold is determined below and then put into the model as hardwired (not used to determine the threshold - no loops here) so that we can export the model at the same time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedim=14\n",
    "hiddim=encodedim//2\n",
    "learnrate=0.001\n",
    "droprate=0.2\n",
    "thresh=0.2 #picked as just above max value to detect anything outside the norm\n",
    "threshold=tf.constant(thresh)\n",
    "inputs=tf.placeholder(tf.float32, shape=(None,numinps),name=\"inputs\")\n",
    "#mode=tf.placeholder(tf.string, name=\"mode\")\n",
    "\n",
    "dense0 = tf.layers.dense(inputs=inputs, units=encodedim, activation=tf.nn.tanh)\n",
    "dropout0 = tf.layers.dropout(inputs=dense0, rate=droprate)\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=dropout0, units=hiddim, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=droprate)\n",
    "\n",
    "dense2 = tf.layers.dense(inputs=dropout1, units=hiddim, activation=tf.nn.tanh)\n",
    "dropout2 = tf.layers.dropout(inputs=dense2, rate=droprate)\n",
    "\n",
    "dense3 = tf.layers.dense(inputs=dropout2, units=numinps, activation=tf.nn.relu)\n",
    "dropout3 = tf.layers.dropout(inputs=dense3, rate=droprate)\n",
    "\n",
    "loss=tf.losses.mean_squared_error(labels=inputs,predictions=dropout3)\n",
    "Yout=tf.cast(tf.math.greater(loss,threshold), tf.int32)\n",
    "trainstep=tf.train.AdamOptimizer(learning_rate=learnrate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Training Autoencoder and then exporting saved_model format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0 0 0.28415745\n",
      "evalu:  0 0 [0.26221836]\n",
      "train:  0 1 0.2538927\n",
      "train:  0 2 0.24496499\n",
      "train:  0 3 0.25430876\n",
      "train:  0 4 0.23816213\n",
      "train:  0 5 0.24716203\n",
      "train:  0 6 0.23803094\n",
      "train:  0 7 0.23084171\n",
      "train:  0 8 0.22942352\n",
      "train:  0 9 0.23681481\n",
      "train:  0 10 0.2153223\n",
      "train:  0 11 0.2252487\n",
      "train:  0 12 0.21585816\n",
      "train:  0 13 0.22397712\n",
      "train:  0 14 0.20839891\n",
      "train:  0 15 0.21995819\n",
      "train:  0 16 0.21143016\n",
      "train:  0 17 0.21330862\n",
      "train:  0 18 0.2128655\n",
      "train:  0 19 0.21806867\n",
      "train:  0 20 0.21082042\n",
      "evalu:  0 20 [0.20626444]\n",
      "train:  0 21 0.20520078\n",
      "train:  0 22 0.20046498\n",
      "train:  0 23 0.18976857\n",
      "train:  0 24 0.19944838\n",
      "train:  0 25 0.1918441\n",
      "train:  0 26 0.19970296\n",
      "train:  0 27 0.19915324\n",
      "train:  0 28 0.2016513\n",
      "train:  0 29 0.1976281\n",
      "train:  0 30 0.18666369\n",
      "train:  0 31 0.18188588\n",
      "train:  0 32 0.18492953\n",
      "train:  0 33 0.18744393\n",
      "train:  0 34 0.18916576\n",
      "train:  0 35 0.17864166\n",
      "train:  0 36 0.17437503\n",
      "train:  0 37 0.1777041\n",
      "train:  0 38 0.1691256\n",
      "train:  0 39 0.16708131\n",
      "train:  0 40 0.16489813\n",
      "evalu:  0 40 [0.16986068]\n",
      "train:  0 41 0.1655141\n",
      "train:  0 42 0.16751282\n",
      "train:  0 43 0.16127707\n",
      "train:  0 44 0.1665725\n",
      "train:  0 45 0.16682658\n",
      "train:  0 46 0.16911864\n",
      "train:  0 47 0.16907959\n",
      "train:  0 48 0.16508321\n",
      "train:  0 49 0.15952617\n",
      "train:  0 50 0.1611882\n",
      "train:  0 51 0.1627167\n",
      "train:  0 52 0.15927246\n",
      "train:  0 53 0.15812412\n",
      "train:  0 54 0.1560359\n",
      "train:  0 55 0.15414873\n",
      "train:  0 56 0.15941726\n",
      "train:  0 57 0.15765527\n",
      "train:  0 58 0.1632683\n",
      "train:  0 59 0.16247271\n",
      "train:  0 60 0.15779418\n",
      "evalu:  0 60 [0.15729056]\n",
      "train:  0 61 0.16208951\n",
      "train:  0 62 0.15266873\n",
      "train:  0 63 0.15634578\n",
      "train:  0 64 0.15667339\n",
      "train:  0 65 0.15663603\n",
      "train:  0 66 0.1549488\n",
      "train:  0 67 0.15782508\n",
      "train:  0 68 0.15662836\n",
      "train:  0 69 0.15761496\n",
      "train:  0 70 0.15900096\n",
      "train:  0 71 0.15582547\n",
      "train:  0 72 0.15254097\n",
      "train:  0 73 0.15176263\n",
      "train:  0 74 0.15114453\n",
      "train:  0 75 0.15600166\n",
      "train:  0 76 0.1578581\n",
      "train:  0 77 0.15489186\n",
      "train:  0 78 0.1505628\n",
      "train:  0 79 0.15410739\n",
      "train:  0 80 0.14852834\n",
      "evalu:  0 80 [0.15292707]\n",
      "train:  0 81 0.15172666\n",
      "train:  0 82 0.14942254\n",
      "train:  0 83 0.15703002\n",
      "train:  0 84 0.15163842\n",
      "train:  0 85 0.14665619\n",
      "train:  0 86 0.15417515\n",
      "train:  0 87 0.15207164\n",
      "train:  0 88 0.15508294\n",
      "train:  0 89 0.15114705\n",
      "train:  0 90 0.16217051\n",
      "train:  0 91 0.15065758\n",
      "train:  0 92 0.15172832\n",
      "train:  0 93 0.15716384\n",
      "train:  0 94 0.14837405\n",
      "train:  0 95 0.15388575\n",
      "train:  0 96 0.15226004\n",
      "train:  0 97 0.15591115\n",
      "train:  0 98 0.14887816\n",
      "train:  0 99 0.14657818\n",
      "train:  0 100 0.1500868\n",
      "evalu:  0 100 [0.15043308]\n",
      "train:  0 101 0.14730886\n",
      "train:  0 102 0.1550689\n",
      "train:  0 103 0.15152496\n",
      "train:  0 104 0.1439694\n",
      "train:  0 105 0.15614475\n",
      "train:  0 106 0.15018891\n",
      "train:  0 107 0.14538117\n",
      "train:  0 108 0.15267971\n",
      "train:  0 109 0.15089193\n",
      "train:  0 110 0.1481868\n",
      "train:  0 111 0.15162513\n",
      "train:  0 112 0.14504123\n",
      "train:  0 113 0.15274037\n",
      "train:  0 114 0.14333972\n",
      "train:  0 115 0.15564989\n",
      "train:  0 116 0.15237698\n",
      "train:  0 117 0.14654317\n",
      "train:  0 118 0.14711984\n",
      "train:  0 119 0.1470584\n",
      "train:  0 120 0.13493432\n",
      "evalu:  0 120 [0.14720039]\n",
      "train:  0 121 0.14621474\n",
      "train:  0 122 0.14674099\n",
      "train:  0 123 0.14878522\n",
      "train:  0 124 0.1474237\n",
      "train:  0 125 0.14237234\n",
      "train:  0 126 0.1499255\n",
      "train:  0 127 0.1415299\n",
      "train:  0 128 0.14315085\n",
      "train:  0 129 0.14323686\n",
      "train:  0 130 0.13501358\n",
      "train:  0 131 0.13120243\n",
      "train:  0 132 0.13300242\n",
      "train:  0 133 0.1309994\n",
      "train:  0 134 0.1298255\n",
      "train:  0 135 0.12564023\n",
      "train:  0 136 0.122020274\n",
      "train:  0 137 0.12117472\n",
      "train:  0 138 0.12100079\n",
      "train:  0 139 0.11804604\n",
      "train:  0 140 0.11557294\n",
      "evalu:  0 140 [0.11784553]\n",
      "train:  0 141 0.11694138\n",
      "train:  0 142 0.11162898\n",
      "train:  0 143 0.12108612\n",
      "train:  0 144 0.11339513\n",
      "train:  0 145 0.112704076\n",
      "train:  0 146 0.11241328\n",
      "train:  0 147 0.1088255\n",
      "train:  0 148 0.11191955\n",
      "train:  0 149 0.11306722\n",
      "train:  0 150 0.113703154\n",
      "train:  0 151 0.11138967\n",
      "train:  0 152 0.11447502\n",
      "train:  0 153 0.110271744\n",
      "train:  0 154 0.11242828\n",
      "train:  0 155 0.10913325\n",
      "train:  0 156 0.108521864\n",
      "train:  0 157 0.11185792\n",
      "train:  1 0 0.11263131\n",
      "evalu:  1 0 [0.10736302]\n",
      "train:  1 1 0.10611362\n",
      "train:  1 2 0.101148784\n",
      "train:  1 3 0.10625072\n",
      "train:  1 4 0.102347426\n",
      "train:  1 5 0.10893617\n",
      "train:  1 6 0.10498861\n",
      "train:  1 7 0.10382343\n",
      "train:  1 8 0.10464062\n",
      "train:  1 9 0.10934764\n",
      "train:  1 10 0.104207754\n",
      "train:  1 11 0.109525025\n",
      "train:  1 12 0.10207913\n",
      "train:  1 13 0.10917444\n",
      "train:  1 14 0.10206664\n",
      "train:  1 15 0.103566565\n",
      "train:  1 16 0.10392442\n",
      "train:  1 17 0.10249902\n",
      "train:  1 18 0.108502604\n",
      "train:  1 19 0.108501144\n",
      "train:  1 20 0.103300765\n",
      "evalu:  1 20 [0.10474439]\n",
      "train:  1 21 0.10798321\n",
      "train:  1 22 0.10588221\n",
      "train:  1 23 0.10271893\n",
      "train:  1 24 0.10369578\n",
      "train:  1 25 0.1037818\n",
      "train:  1 26 0.10258293\n",
      "train:  1 27 0.10704717\n",
      "train:  1 28 0.107690714\n",
      "train:  1 29 0.10512569\n",
      "train:  1 30 0.10655779\n",
      "train:  1 31 0.105167896\n",
      "train:  1 32 0.104660444\n",
      "train:  1 33 0.10462225\n",
      "train:  1 34 0.1039345\n",
      "train:  1 35 0.10359148\n",
      "train:  1 36 0.10319888\n",
      "train:  1 37 0.10675506\n",
      "train:  1 38 0.10034196\n",
      "train:  1 39 0.0961017\n",
      "train:  1 40 0.09960225\n",
      "evalu:  1 40 [0.10239199]\n",
      "train:  1 41 0.10313441\n",
      "train:  1 42 0.10029086\n",
      "train:  1 43 0.096805625\n",
      "train:  1 44 0.10278768\n",
      "train:  1 45 0.10157073\n",
      "train:  1 46 0.10545776\n",
      "train:  1 47 0.105372295\n",
      "train:  1 48 0.10181965\n",
      "train:  1 49 0.10526767\n",
      "train:  1 50 0.09993249\n",
      "train:  1 51 0.099350385\n",
      "train:  1 52 0.098104954\n",
      "train:  1 53 0.09986705\n",
      "train:  1 54 0.09681937\n",
      "train:  1 55 0.09755878\n",
      "train:  1 56 0.100718774\n",
      "train:  1 57 0.100014426\n",
      "train:  1 58 0.103746\n",
      "train:  1 59 0.10448868\n",
      "train:  1 60 0.097249486\n",
      "evalu:  1 60 [0.09996329]\n",
      "train:  1 61 0.10567037\n",
      "train:  1 62 0.09683638\n",
      "train:  1 63 0.10199952\n",
      "train:  1 64 0.102599114\n",
      "train:  1 65 0.102978826\n",
      "train:  1 66 0.10292716\n",
      "train:  1 67 0.10043905\n",
      "train:  1 68 0.102162875\n",
      "train:  1 69 0.10324365\n",
      "train:  1 70 0.10193432\n",
      "train:  1 71 0.099032365\n",
      "train:  1 72 0.095810995\n",
      "train:  1 73 0.09378525\n",
      "train:  1 74 0.09743162\n",
      "train:  1 75 0.100802265\n",
      "train:  1 76 0.101321824\n",
      "train:  1 77 0.1000444\n",
      "train:  1 78 0.0968692\n",
      "train:  1 79 0.09563068\n",
      "train:  1 80 0.09281464\n",
      "evalu:  1 80 [0.09766949]\n",
      "train:  1 81 0.094503224\n",
      "train:  1 82 0.09262936\n",
      "train:  1 83 0.10247392\n",
      "train:  1 84 0.097300045\n",
      "train:  1 85 0.092884116\n",
      "train:  1 86 0.10078081\n",
      "train:  1 87 0.09847278\n",
      "train:  1 88 0.100239746\n",
      "train:  1 89 0.096891105\n",
      "train:  1 90 0.10431166\n",
      "train:  1 91 0.097166345\n",
      "train:  1 92 0.09636748\n",
      "train:  1 93 0.10206926\n",
      "train:  1 94 0.09536218\n",
      "train:  1 95 0.0980238\n",
      "train:  1 96 0.09464566\n",
      "train:  1 97 0.1005965\n",
      "train:  1 98 0.09456514\n",
      "train:  1 99 0.09438643\n",
      "train:  1 100 0.09854359\n",
      "evalu:  1 100 [0.09569261]\n",
      "train:  1 101 0.09712073\n",
      "train:  1 102 0.097685546\n",
      "train:  1 103 0.09786942\n",
      "train:  1 104 0.090673484\n",
      "train:  1 105 0.09797888\n",
      "train:  1 106 0.09428878\n",
      "train:  1 107 0.08968345\n",
      "train:  1 108 0.098744005\n",
      "train:  1 109 0.097382516\n",
      "train:  1 110 0.09241861\n",
      "train:  1 111 0.09589718\n",
      "train:  1 112 0.091283895\n",
      "train:  1 113 0.09577889\n",
      "train:  1 114 0.09170189\n",
      "train:  1 115 0.10017865\n",
      "train:  1 116 0.100313045\n",
      "train:  1 117 0.0931714\n",
      "train:  1 118 0.09498715\n",
      "train:  1 119 0.094542675\n",
      "train:  1 120 0.086396806\n",
      "evalu:  1 120 [0.09405133]\n",
      "train:  1 121 0.09469175\n",
      "train:  1 122 0.0969654\n",
      "train:  1 123 0.09904095\n",
      "train:  1 124 0.09621634\n",
      "train:  1 125 0.09017139\n",
      "train:  1 126 0.095503\n",
      "train:  1 127 0.092119254\n",
      "train:  1 128 0.0957006\n",
      "train:  1 129 0.097862564\n",
      "train:  1 130 0.090112686\n",
      "train:  1 131 0.090908654\n",
      "train:  1 132 0.095859446\n",
      "train:  1 133 0.09451713\n",
      "train:  1 134 0.09532306\n",
      "train:  1 135 0.09458168\n",
      "train:  1 136 0.09338126\n",
      "train:  1 137 0.09461913\n",
      "train:  1 138 0.09144606\n",
      "train:  1 139 0.090144575\n",
      "train:  1 140 0.09005288\n",
      "evalu:  1 140 [0.09280074]\n",
      "train:  1 141 0.09600698\n",
      "train:  1 142 0.08694167\n",
      "train:  1 143 0.09600459\n",
      "train:  1 144 0.09121575\n",
      "train:  1 145 0.089651376\n",
      "train:  1 146 0.092920326\n",
      "train:  1 147 0.088517405\n",
      "train:  1 148 0.09352087\n",
      "train:  1 149 0.0929341\n",
      "train:  1 150 0.09561791\n",
      "train:  1 151 0.094155\n",
      "train:  1 152 0.0969199\n",
      "train:  1 153 0.093853034\n",
      "train:  1 154 0.09530265\n",
      "train:  1 155 0.09217667\n",
      "train:  1 156 0.09342273\n",
      "train:  1 157 0.09546513\n",
      "train:  2 0 0.09724524\n",
      "evalu:  2 0 [0.091914624]\n",
      "train:  2 1 0.09015235\n",
      "train:  2 2 0.08624903\n",
      "train:  2 3 0.09263114\n",
      "train:  2 4 0.08752868\n",
      "train:  2 5 0.09426583\n",
      "train:  2 6 0.09095505\n",
      "train:  2 7 0.08827339\n",
      "train:  2 8 0.08905894\n",
      "train:  2 9 0.09579449\n",
      "train:  2 10 0.09066937\n",
      "train:  2 11 0.09379165\n",
      "train:  2 12 0.088534646\n",
      "train:  2 13 0.09510557\n",
      "train:  2 14 0.08909128\n",
      "train:  2 15 0.09180769\n",
      "train:  2 16 0.09187507\n",
      "train:  2 17 0.08818118\n",
      "train:  2 18 0.09464851\n",
      "train:  2 19 0.09492023\n",
      "train:  2 20 0.089582324\n",
      "evalu:  2 20 [0.091164954]\n",
      "train:  2 21 0.09228208\n",
      "train:  2 22 0.09170805\n",
      "train:  2 23 0.08785387\n",
      "train:  2 24 0.090865396\n",
      "train:  2 25 0.08883811\n",
      "train:  2 26 0.09013274\n",
      "train:  2 27 0.09302648\n",
      "train:  2 28 0.09405918\n",
      "train:  2 29 0.09410907\n",
      "train:  2 30 0.093692824\n",
      "train:  2 31 0.091152176\n",
      "train:  2 32 0.09064181\n",
      "train:  2 33 0.09136751\n",
      "train:  2 34 0.09103086\n",
      "train:  2 35 0.091252096\n",
      "train:  2 36 0.09033763\n",
      "train:  2 37 0.09468358\n",
      "train:  2 38 0.089209646\n",
      "train:  2 39 0.08372728\n",
      "train:  2 40 0.087318964\n",
      "evalu:  2 40 [0.090577066]\n",
      "train:  2 41 0.08980702\n",
      "train:  2 42 0.08933541\n",
      "train:  2 43 0.08423248\n",
      "train:  2 44 0.09177226\n",
      "train:  2 45 0.08913461\n",
      "train:  2 46 0.093332775\n",
      "train:  2 47 0.09408715\n",
      "train:  2 48 0.09075609\n",
      "train:  2 49 0.09417345\n",
      "train:  2 50 0.08950234\n",
      "train:  2 51 0.08886032\n",
      "train:  2 52 0.08829185\n",
      "train:  2 53 0.09029983\n",
      "train:  2 54 0.08804535\n",
      "train:  2 55 0.08838501\n",
      "train:  2 56 0.091333784\n",
      "train:  2 57 0.09060644\n",
      "train:  2 58 0.09338916\n",
      "train:  2 59 0.094300605\n",
      "train:  2 60 0.0864426\n",
      "evalu:  2 60 [0.09012317]\n",
      "train:  2 61 0.09640588\n",
      "train:  2 62 0.086974114\n",
      "train:  2 63 0.09157828\n",
      "train:  2 64 0.0927781\n",
      "train:  2 65 0.09385187\n",
      "train:  2 66 0.0937327\n",
      "train:  2 67 0.09144582\n",
      "train:  2 68 0.092976\n",
      "train:  2 69 0.09416816\n",
      "train:  2 70 0.0929229\n",
      "train:  2 71 0.089819945\n",
      "train:  2 72 0.08702772\n",
      "train:  2 73 0.08460082\n",
      "train:  2 74 0.08955514\n",
      "train:  2 75 0.09254683\n",
      "train:  2 76 0.094064\n",
      "train:  2 77 0.092635565\n",
      "train:  2 78 0.0894288\n",
      "train:  2 79 0.08701153\n",
      "train:  2 80 0.0841912\n",
      "evalu:  2 80 [0.0897444]\n",
      "train:  2 81 0.08537472\n",
      "train:  2 82 0.08465025\n",
      "train:  2 83 0.09396239\n",
      "train:  2 84 0.08992136\n",
      "train:  2 85 0.085562885\n",
      "train:  2 86 0.09320176\n",
      "train:  2 87 0.09089367\n",
      "train:  2 88 0.09291761\n",
      "train:  2 89 0.089594625\n",
      "train:  2 90 0.096854754\n",
      "train:  2 91 0.09064761\n",
      "train:  2 92 0.09017157\n",
      "train:  2 93 0.095483586\n",
      "train:  2 94 0.08927092\n",
      "train:  2 95 0.09188807\n",
      "train:  2 96 0.087386064\n",
      "train:  2 97 0.09427198\n",
      "train:  2 98 0.08831128\n",
      "train:  2 99 0.08769104\n",
      "train:  2 100 0.09173233\n",
      "evalu:  2 100 [0.08943433]\n",
      "train:  2 101 0.09122017\n",
      "train:  2 102 0.09118189\n",
      "train:  2 103 0.09142596\n",
      "train:  2 104 0.084561646\n",
      "train:  2 105 0.09176305\n",
      "train:  2 106 0.088488385\n",
      "train:  2 107 0.08348337\n",
      "train:  2 108 0.09269737\n",
      "train:  2 109 0.09109699\n",
      "train:  2 110 0.0863486\n",
      "train:  2 111 0.089532845\n",
      "train:  2 112 0.08642239\n",
      "train:  2 113 0.089690425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  2 114 0.087539725\n",
      "train:  2 115 0.0946579\n",
      "train:  2 116 0.09481533\n",
      "train:  2 117 0.08830567\n",
      "train:  2 118 0.08959347\n",
      "train:  2 119 0.09027308\n",
      "train:  2 120 0.081570305\n",
      "evalu:  2 120 [0.0891635]\n",
      "train:  2 121 0.09034017\n",
      "train:  2 122 0.09150728\n",
      "train:  2 123 0.09428333\n",
      "train:  2 124 0.091353565\n",
      "train:  2 125 0.0855011\n",
      "train:  2 126 0.090693444\n",
      "train:  2 127 0.08847911\n",
      "train:  2 128 0.09101873\n",
      "train:  2 129 0.09322715\n",
      "train:  2 130 0.08589445\n",
      "train:  2 131 0.08638716\n",
      "train:  2 132 0.091145836\n",
      "train:  2 133 0.090547845\n",
      "train:  2 134 0.09087426\n",
      "train:  2 135 0.0910946\n",
      "train:  2 136 0.08899118\n",
      "train:  2 137 0.09109343\n",
      "train:  2 138 0.08782264\n",
      "train:  2 139 0.08624077\n",
      "train:  2 140 0.08618146\n",
      "evalu:  2 140 [0.08893228]\n",
      "train:  2 141 0.09178348\n",
      "train:  2 142 0.0834552\n",
      "train:  2 143 0.091796495\n",
      "train:  2 144 0.087336935\n",
      "train:  2 145 0.085897796\n",
      "train:  2 146 0.08961163\n",
      "train:  2 147 0.08555917\n",
      "train:  2 148 0.09023733\n",
      "train:  2 149 0.088879436\n",
      "train:  2 150 0.091844976\n",
      "train:  2 151 0.09100079\n",
      "train:  2 152 0.09320382\n",
      "train:  2 153 0.09085132\n",
      "train:  2 154 0.09143592\n",
      "train:  2 155 0.089109324\n",
      "train:  2 156 0.09016017\n",
      "train:  2 157 0.09221798\n",
      "train:  3 0 0.09403136\n",
      "evalu:  3 0 [0.08873352]\n",
      "train:  3 1 0.087005615\n",
      "train:  3 2 0.083628245\n",
      "train:  3 3 0.08982139\n",
      "train:  3 4 0.08423178\n",
      "train:  3 5 0.09108412\n",
      "train:  3 6 0.08789702\n",
      "train:  3 7 0.08518247\n",
      "train:  3 8 0.086100325\n",
      "train:  3 9 0.09291262\n",
      "train:  3 10 0.08748787\n",
      "train:  3 11 0.09061593\n",
      "train:  3 12 0.0858458\n",
      "train:  3 13 0.09221939\n",
      "train:  3 14 0.0864948\n",
      "train:  3 15 0.0894714\n",
      "train:  3 16 0.08935942\n",
      "train:  3 17 0.08569033\n",
      "train:  3 18 0.09221196\n",
      "train:  3 19 0.091898344\n",
      "train:  3 20 0.08713054\n",
      "evalu:  3 20 [0.08853302]\n",
      "train:  3 21 0.0894801\n",
      "train:  3 22 0.089452155\n",
      "train:  3 23 0.08561373\n",
      "train:  3 24 0.08847857\n",
      "train:  3 25 0.085988924\n",
      "train:  3 26 0.08752673\n",
      "train:  3 27 0.09046757\n",
      "train:  3 28 0.09149424\n",
      "train:  3 29 0.09159924\n",
      "train:  3 30 0.09095752\n",
      "train:  3 31 0.0886678\n",
      "train:  3 32 0.08809338\n",
      "train:  3 33 0.08869515\n",
      "train:  3 34 0.088364646\n",
      "train:  3 35 0.0890245\n",
      "train:  3 36 0.087975435\n",
      "train:  3 37 0.092758484\n",
      "train:  3 38 0.08742186\n",
      "train:  3 39 0.08154783\n",
      "train:  3 40 0.08507746\n",
      "evalu:  3 40 [0.0883478]\n",
      "train:  3 41 0.08717882\n",
      "train:  3 42 0.08741413\n",
      "train:  3 43 0.08239415\n",
      "train:  3 44 0.089745864\n",
      "train:  3 45 0.08689332\n",
      "train:  3 46 0.09078654\n",
      "train:  3 47 0.091832355\n",
      "train:  3 48 0.088521406\n",
      "train:  3 49 0.092094965\n",
      "train:  3 50 0.08754326\n",
      "train:  3 51 0.086840026\n",
      "train:  3 52 0.0862293\n",
      "train:  3 53 0.08832946\n",
      "train:  3 54 0.0862046\n",
      "train:  3 55 0.08665244\n",
      "train:  3 56 0.08966514\n",
      "train:  3 57 0.0887935\n",
      "train:  3 58 0.0913474\n",
      "train:  3 59 0.09237955\n",
      "train:  3 60 0.084268525\n",
      "evalu:  3 60 [0.088173084]\n",
      "train:  3 61 0.0943053\n",
      "train:  3 62 0.08517068\n",
      "train:  3 63 0.08973836\n",
      "train:  3 64 0.090712234\n",
      "train:  3 65 0.091945946\n",
      "train:  3 66 0.09197457\n",
      "train:  3 67 0.089537136\n",
      "train:  3 68 0.09142452\n",
      "train:  3 69 0.092486635\n",
      "train:  3 70 0.0909425\n",
      "train:  3 71 0.08798734\n",
      "train:  3 72 0.08528892\n",
      "train:  3 73 0.08286745\n",
      "train:  3 74 0.08764065\n",
      "train:  3 75 0.09058655\n",
      "train:  3 76 0.09266552\n",
      "train:  3 77 0.09084313\n",
      "train:  3 78 0.08795983\n",
      "train:  3 79 0.08509011\n",
      "train:  3 80 0.08229968\n",
      "evalu:  3 80 [0.08799674]\n",
      "train:  3 81 0.08347355\n",
      "train:  3 82 0.083069935\n",
      "train:  3 83 0.09230508\n",
      "train:  3 84 0.08823608\n",
      "train:  3 85 0.083951265\n",
      "train:  3 86 0.091120735\n",
      "train:  3 87 0.08934255\n",
      "train:  3 88 0.09130849\n",
      "train:  3 89 0.08798645\n",
      "train:  3 90 0.09491502\n",
      "train:  3 91 0.089298755\n",
      "train:  3 92 0.08880964\n",
      "train:  3 93 0.09379532\n",
      "train:  3 94 0.08741381\n",
      "train:  3 95 0.09033683\n",
      "train:  3 96 0.08581894\n",
      "train:  3 97 0.09297415\n",
      "train:  3 98 0.08694976\n",
      "train:  3 99 0.086004384\n",
      "train:  3 100 0.08979815\n",
      "evalu:  3 100 [0.08783511]\n",
      "train:  3 101 0.08963192\n",
      "train:  3 102 0.0897187\n",
      "train:  3 103 0.08985282\n",
      "train:  3 104 0.083107755\n",
      "train:  3 105 0.09011735\n",
      "train:  3 106 0.087020956\n",
      "train:  3 107 0.0820307\n",
      "train:  3 108 0.091283806\n",
      "train:  3 109 0.089587115\n",
      "train:  3 110 0.08481494\n",
      "train:  3 111 0.088063516\n",
      "train:  3 112 0.08509623\n",
      "train:  3 113 0.088119775\n",
      "train:  3 114 0.08622774\n",
      "train:  3 115 0.09309758\n",
      "train:  3 116 0.09350255\n",
      "train:  3 117 0.086950935\n",
      "train:  3 118 0.08801079\n",
      "train:  3 119 0.08872777\n",
      "train:  3 120 0.080259226\n",
      "evalu:  3 120 [0.087680586]\n",
      "train:  3 121 0.08902619\n",
      "train:  3 122 0.090192385\n",
      "train:  3 123 0.09287098\n",
      "train:  3 124 0.089709915\n",
      "train:  3 125 0.084233396\n",
      "train:  3 126 0.08931572\n",
      "train:  3 127 0.08708856\n",
      "train:  3 128 0.08969283\n",
      "train:  3 129 0.09193001\n",
      "train:  3 130 0.084682144\n",
      "train:  3 131 0.08491105\n",
      "train:  3 132 0.0896446\n",
      "train:  3 133 0.08910963\n",
      "train:  3 134 0.08946732\n",
      "train:  3 135 0.08963819\n",
      "train:  3 136 0.08727024\n",
      "train:  3 137 0.08975605\n",
      "train:  3 138 0.08640125\n",
      "train:  3 139 0.08471254\n",
      "train:  3 140 0.084958\n",
      "evalu:  3 140 [0.08753473]\n",
      "train:  3 141 0.090453476\n",
      "train:  3 142 0.08228968\n",
      "train:  3 143 0.090254806\n",
      "train:  3 144 0.086152166\n",
      "train:  3 145 0.084516466\n",
      "train:  3 146 0.08825359\n",
      "train:  3 147 0.08443862\n",
      "train:  3 148 0.089000314\n",
      "train:  3 149 0.08747099\n",
      "train:  3 150 0.090536855\n",
      "train:  3 151 0.08978359\n",
      "train:  3 152 0.09186741\n",
      "train:  3 153 0.089714274\n",
      "train:  3 154 0.08999651\n",
      "train:  3 155 0.08787832\n",
      "train:  3 156 0.088657126\n",
      "train:  3 157 0.09090907\n",
      "Running Test data...\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: m_53969/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batchsize=100\n",
    "#xbatch=dftrain2.loc[:,cols].head(10).values\n",
    "evalbatch=dfeval[cols]\n",
    "numepochs=4\n",
    "\n",
    "treerr=[]\n",
    "everr=[]\n",
    "modeldir=\"m_{:05d}\".format(np.random.randint(100000))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(numepochs):\n",
    "        for i in range(dftrain2.shape[0]//batchsize):\n",
    "            xbatch=dftrain2.iloc[i*batchsize:(i+1)*batchsize][cols]\n",
    "            _,ltr=sess.run([trainstep,loss],feed_dict={inputs:xbatch})\n",
    "            print(\"train: \",epoch,i,ltr)\n",
    "            if i%20==0:\n",
    "                l=sess.run([loss],feed_dict={inputs:evalbatch})\n",
    "                print(\"evalu: \",epoch,i,l)\n",
    "                treerr.append(ltr)\n",
    "                everr.append(l)\n",
    "     \n",
    "    print(\"Running Test data...\")\n",
    "    out=[]\n",
    "    for i in range(dftest.shape[0]):\n",
    "        testbatch=np.array([dftest.iloc[i][cols].values])\n",
    "        l=sess.run([loss,Yout],feed_dict={inputs:testbatch})\n",
    "        out.append([dftest.iloc[i]['Class'],l[0]])\n",
    "    tf.saved_model.simple_save(sess,modeldir, inputs=\n",
    "                           {\n",
    "                               \"inputs\":inputs#,'labels':labels,\"learnrate\":learnrate,\"droprate\":droprate,\"mode\":mode\n",
    "                           },\n",
    "                           outputs={\"Yout\":Yout}#,\"batchloss\":batchloss}\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2edfed30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VOW9x/HPb7KShOxhMSELiGwBA4bdra7YRa07ivutba3dbK12uXpr23u92lZ777Uq1qXudcPSutd9ASSyBwQCZCMsIQmB7JnM7/5xTmCICZlAYJLM7/16zStznrPMc5wX8/U85znPI6qKMcYY4wl2BYwxxvQNFgjGGGMACwRjjDEuCwRjjDGABYIxxhiXBYIxxhjAAsEYY4zLAsEYYwxggWCMMcYVHuwK9ERqaqpmZ2cHuxrGGNOvfP7557tUNa277fpVIGRnZ1NQUBDsahhjTL8iIiWBbGdNRsYYYwALBGOMMS4LBGOMMYAFgjHGGJcFgjHGGMACwRhjjMsCwRhjDBAigfDK8q08tTigbrjGGBOyQiIQXl+zjcc/LQ52NYwxpk8LiUDISomltLoBn0+DXRVjjOmzQiQQYmjx+tixtynYVTHGmD4rNAIhORaA4l0NQa6JMcb0XaERCCkxAJRW1we5JsYY03cFFAgiMkdE1otIkYjc1sn6m0VkrYisEpF3RCTLLf+KiKzwezWJyPnuusdFZIvfurzePbX9hidEExEmFFfZFYIxxnSl2+GvRSQMuB84EygHlorIQlVd67fZciBfVRtE5LvA3cClqvoekOceJxkoAt7y2+8WVX2xd06la+FhHjKSYii1QDDGmC4FcoUwDShS1c2q2gI8B5znv4Gqvqeq7b+2i4GMTo5zEfC633ZHVWZyDCXWZGSMMV0KJBDSgTK/5XK3rCvXA693Un4Z8GyHst+5zUz3ikhUAHU5ZNkpMZTsakDVup4aY0xnAgkE6aSs019VEZkH5AP3dCgfDkwE3vQr/jkwFpgKJAO3dnHMG0SkQEQKKisrA6hu5zJTYtnb7KWmofWQj2GMMQNZIIFQDozwW84AKjpuJCJnAL8EzlXV5g6rLwEWqOq+X2NV3aaOZuAxnKapL1HV+aqar6r5aWndTgnapaxkp6dRSZU1GxljTGcCCYSlwGgRyRGRSJymn4X+G4jIZOAhnDDY2ckx5tKhuci9akBEBDgfWNPz6gcuO7U9EOzGsjHGdKbbXkaq6hWRm3Cae8KAR1W1UETuBApUdSFOE1Ec8ILz+06pqp4LICLZOFcYH3Q49NMikobTJLUC+E6vnFEXMpJiELFAMMaYrnQbCACq+hrwWoey2/3en3GQfYvp5Ca0qp4WcC17QXREGMPio62nkTHGdCEknlRul5USY1cIxhjThdAKhORYCwRjjOlCSAVCZkoMu+qaqW/2BrsqxhjT54RUIGSnOKOe2lWCMcZ8WUgFgo16aowxXQupQMh0A8FGPTXGmC8LjUCo2gRbPyc+OoLk2EhrMjLGmE6ERiC89lP4548BZ9RTazIyxpgvC41AGDoBdn4BbV6yUmJsKk1jjOlEiARCLrQ1Q1URWSmxbKttpMXrC3atjDGmTwmdQADYsYas5Bh8CuU1dpVgjDH+QiMQUo8DT7gTCCk26qkxxnQmNAIhPBJSx8COQrL2PZxmN5aNMcZfaAQCwLBc2FFIalwkMZFhlFTbFYIxxvgLnUAYOgH2bEUaa8hMtlFPjTGmo9AKBIAdhWSnxFqTkTHGdBBQIIjIHBFZLyJFInJbJ+tvFpG1IrJKRN4RkSy/dW0issJ9LfQrzxGRJSKyUUT+5k7PeeQMnej83VFIVkoMZdWNtPn0iH6kMcb0J90GgoiEAfcD5wDjgbkiMr7DZsuBfFWdBLwI3O23rlFV89zXuX7l/w3cq6qjgRrg+sM4j+7FDYGYVNixmsyUGFrafGzf03REP9IYY/qTQK4QpgFFqrpZVVuA54Dz/DdQ1fdUtb1RfjGQcbADijPx8mk44QHwV+D8nlS8x0ScZiO3yQisp5ExxvgLJBDSgTK/5XI6mSPZz/XA637L0SJSICKLRaT9Rz8F2K2q7TPVdHlMEbnB3b+gsrIygOoexLCJsHMdmYlRgD2LYIwx/sID2EY6Keu08V1E5gH5wCl+xZmqWiEiI4F3RWQ1sCfQY6rqfGA+QH5+/uE1+g+dAN4mjvFVEBEmFgjGGOMnkCuEcmCE33IGUNFxIxE5A/glcK6qNreXq2qF+3cz8D4wGdgFJIpIeyB1esxe5/Y0CttZyIgkG/XUGGP8BRIIS4HRbq+gSOAyYKH/BiIyGXgIJwx2+pUniUiU+z4VmA2sVVUF3gMucje9Gvj74Z5Mt9LGgoTBjkIybdRTY4w5QLeB4Lbz3wS8CawDnlfVQhG5U0Taew3dA8QBL3ToXjoOKBCRlTgBcJeqrnXX3QrcLCJFOPcUHum1s+pKeJQzrtGONWSnxFJa3YCTTcYYYwK5h4Cqvga81qHsdr/3Z3Sx36fAxC7WbcbpwXR0DcuF0sVkZsZQ1+ylur6FlLioo14NY4zpa0LnSeV2QydAbRmjBjsdnGx+ZWOMcYRgIDhzI4zSEgC7sWyMMa6QDYShjUWI2LMIxhjTLvQCYfAwGJRMROVahsdHWyAYY4wr9AJh3xAWa8iyUU+NMWaf0AsE2DeERXZyFKU2UY4xxgChGghDJ0BrA7kxNeyqa6Gu2dv9PsYYM8CFbiAA48TpaWTNRsYYE6qBkDYOxENGyxYASu3GsjHGhGggRERDymiS6jYA9nCaMcZAqAYCwNAJRFQWkhIbaQ+nGWMMoRwIw3Jhdyljk9RGPTXGGEI5ENwnlqfFbLeup8YYQ0gHgtPTKDe8jIraRpq9bUGukDHGBFfoBkJ8OkQnktNWjCqUVTcGu0bGGBNUAQWCiMwRkfUiUiQit3Wy/mYRWSsiq0TkHRHJcsvzRGSRiBS66y712+dxEdniTqizQkTyeu+0AiACQ3MZ0lAE2KinxhjTbSCISBhwP3AOMB6YKyLjO2y2HMhX1UnAi8DdbnkDcJWqTgDmAPeJSKLffreoap77WnGY59JzQycQu/sLBJ8NcmeMCXmBXCFMA4pUdbOqtgDPAef5b6Cq76lq+y/qYiDDLd+gqhvd9xXATiCttyp/2IblIq0NjImsskAwxoS8QAIhHSjzWy53y7pyPfB6x0IRmQZEApv8in/nNiXdKyJHfx5L98by7ME7bPgKY0zICyQQpJOyTmemF5F5QD5wT4fy4cCTwLWq6nOLfw6MBaYCycCtXRzzBhEpEJGCysrKAKrbA+4QFpMjyymxrqfGmBAXSCCUAyP8ljOAio4bicgZwC+Bc1W12a88HngV+JWqLm4vV9Vt6mgGHsNpmvoSVZ2vqvmqmp+W1sutTZExkDyK0ZRQVt1Am6/TnDPGmJAQSCAsBUaLSI6IRAKXAQv9NxCRycBDOGGw0688ElgAPKGqL3TYZ7j7V4DzgTWHcyKHbOgEjmneTGubsq3Wup4aY0JXt4Ggql7gJuBNYB3wvKoWisidInKuu9k9QBzwgtuFtD0wLgFOBq7ppHvp0yKyGlgNpAK/7b3T6oGhuQxuKCOWRhv11BgT0sID2UhVXwNe61B2u9/7M7rY7yngqS7WnRZ4NY+gYc4QFmOkjOKqBmYdG+T6GGNMkITuk8rt3J5GE8LLKLGH04wxIcwCIWEERCWQH11BiY16aowJYRYIIjB0AuM8pdb11BgT0iwQAIZOIKt1C2VVe1G1rqfGmNBkgQAwdAJRvgYSW3ewq64l2LUxxpigsEAAGDYRgHFSaqOeGmNClgUCwJBxKMI4KbVB7owxIcsCASAyFk0eyThPKcUWCMaYEGWB4PIMnUBueBlFO/cGuyrGGBMUFgjthuaSrtv5omR7sGtijDFBYYHQblguHpT4vUVsr20Kdm2MMeaos0Bo5w5hMdZTyvLSmiBXxhhjjj4LhHYJmWjkYCaGlbDMAsEYE4IsENp5PEjmdE6NWMvy0t3Bro0xxhx1Fgj+jj2D9LatVG3dSIvX1/32xhgzgAQUCCIyR0TWi0iRiNzWyfqbRWStiKwSkXdEJMtv3dUistF9Xe1XfoKIrHaP+T/uzGnBNep0AGbqStZt2xPkyhhjzNHVbSCISBhwP3AOMB6YKyLjO2y2HMhX1UnAi8Dd7r7JwB3AdJw5k+8QkSR3nweAG4DR7mvOYZ/N4UodjXdwOid7Vtl9BGNMyAnkCmEaUKSqm1W1BXgOOM9/A1V9T1XbH/FdDGS4788G3lbValWtAd4G5rjzKcer6iJ1hhd9Amde5eASIXz0GZwUtoaVJbuCXRtjjDmqAgmEdKDMb7ncLevK9cDr3eyb7r4P9JhHz7FnEEsjrSVLgl0TY4w5qgIJhM7a9judNEBE5gH5wD3d7NuTY94gIgUiUlBZWRlAdQ/TyFPwSRhj65dSubf5yH+eMcb0EYEEQjkwwm85A6jouJGInAH8EjhXVZu72bec/c1KXR4TQFXnq2q+quanpaUFUN3DFJ1AfdpkTvassgfUjDEhJZBAWAqMFpEcEYkELgMW+m8gIpOBh3DCYKffqjeBs0Qkyb2ZfBbwpqpuA/aKyAy3d9FVwN974Xx6RfTYM5koW1i3aUuwq2KMMUdNt4Ggql7gJpwf93XA86paKCJ3isi57mb3AHHACyKyQkQWuvtWA7/BCZWlwJ1uGcB3gb8ARcAm9t93CLqI487EI4psfi/YVTHGmKMmPJCNVPU14LUOZbf7vT/jIPs+CjzaSXkBkBtwTY+mY/JoCEsgs3oR3jYf4WH2/J4xZuCzX7rOeMKoHjabWbKKL+wBNWNMiLBA6MKgcWcxRHZTXGjdT40xocECoQvJk84GQDe9E+SaGGPM0WGB0AWJP4byyBzSqz4NdlWMMeaosEA4iMqhJ5HrXUt1TXX3GxtjTD9ngXAQUWPPJFLaKFv2VrCrYowxR5wFwkFkTz6dBo2ibeO/gl0VY4w54iwQDiImJpbCyIkM32X3EYwxA58FQjd2DDmR4d6ttFXZMBbGmIHNAqEbkWPOBKByxatBrokxxhxZFgjdOG5cHmW+NFrX230EY8zAZoHQjazUWJZ48kjbtQTaWoNdHWOMOWIsELohImxPm020rwHKPgt2dYwx5oixQAhA5OhTadUwmr6w5xGMMQOXBUIAJowcwTIdTev6t4NdFWOMOWICCgQRmSMi60WkSERu62T9ySKyTES8InKRX/lX3Alz2l9NInK+u+5xEdnity6v906rdx0/IpGPfJMYXFMIdUdhXmdjjAmCbgNBRMKA+4FzgPHAXBEZ32GzUuAa4Bn/QlV9T1XzVDUPOA1oAPzbXW5pX6+qKw79NI6suKhwShJnOAs2i5oxZoAK5AphGlCkqptVtQV4DjjPfwNVLVbVVYDvIMe5CHhdVRsOubZBNDgnn2oGo0XW/dQYMzAFEgjpQJnfcrlb1lOXAc92KPudiKwSkXtFJOoQjnnU5GUl82HbRNo2vgO+g+WeMcb0T4EEgnRSpj35EBEZDkwE3vQr/jkwFpgKJAO3drHvDSJSICIFlZXBa7+fkpnEh22TCG/cBTtWB60exhhzpAQSCOXACL/lDKCih59zCbBAVfc92aWq29TRDDyG0zT1Jao6X1XzVTU/LS2thx/be0amxrI8coqzUGSzqBljBp5AAmEpMFpEckQkEqfpZ2EPP2cuHZqL3KsGRESA84E1PTzmUeXxCJmZOWzy5MCmd4NdHWOM6XXdBoKqeoGbcJp71gHPq2qhiNwpIucCiMhUESkHLgYeEpHC9v1FJBvnCuODDod+WkRWA6uBVOC3h386R9bkzETebslFSxdB895gV8cYY3pVeCAbqeprwGsdym73e78Upymps32L6eQmtKqe1pOK9gWTM5N40DeJ7/j+4TQbTTg/2FUyxpheY08q90DeiEQKfGPYHT0CXv8Z7OnprRRjjOm7LBB6IGFQBFlDEvl98h3QXAd/mwetTcGuljHG9AoLhB6akpnIq9sT0G8+AFs/h9d+AtqjXrjGGNMnWSD00OTMJGoaWikecgac/DNY/hR89nCwq2WMMYfNAqGHpmQmAfDEomLaTrkNjjsH3rgNtnwU3IoZY8xhskDooeOGxnHBlHQe+6SYS+Yvoewrf4KUUfDC1bC7rPsDGGNMH2WB0EMiwh8vyeNPl+WxYfte5jywnNdz/4C2tcJzl0NLvxy7zxhjLBAO1Xl56bz+o5PITU/gu2/s5f6k29Dtq+EfP7CbzMaYfskC4TBkJMXwzLdmcNs5Y/lTWQ5/9syF1S/Aov8LdtWMMabHAnpS2XQtzCN855RRnDQ6lR89G0P27iLOeet2vCnjiBxzRrCrZ4wxAbMrhF4y4ZgE/vGDk1h5wn+ywZdO07NXs37dqmBXyxhjAmaB0IuiI8L4xflT2Xv+486EEc9dztsffhjsahljTEAsEI6AqVPy8Vz8ODmygzPf/Qbl/3sObHjLZlozxvRpFghHyOAJZ+L70Wr+nnwtEbvWwjMXo/+XD0segqY9wa6eMcZ8iQXCERSdOIyv33Qv/ztxAT9ouYnSxmhnlNQ/jofXb4WqTcGuojHG7GO9jI6wMI/wmwsn88f4WE55dxbfHlXDz5LeJ2zpI87VwuizYOq/QfaJEBkT7OoaY0JYQFcIIjJHRNaLSJGI3NbJ+pNFZJmIeEXkog7r2kRkhfta6FeeIyJLRGSjiPzNnZ5zQBIRfnLWGO74xnge2pTE5VXXs/fG5XDKrVCxDJ65GO7KhEfOgn/9Gor+5QyvbYwxR5FoN0/VikgYsAE4EyjHmWN5rqqu9dsmG4gHfgosVNUX/dbVqWpcJ8d9HnhZVZ8TkQeBlar6wMHqkp+frwUFBQGeWt/09xVb+cnzKzlu6GD+et000gYBWz6E4o+h5BOoWA4+L0gYHJMHWbOdq4fMGRCdEOzqG2P6IRH5XFXzu90ugECYCfyHqp7tLv8cQFX/q5NtHwf+2V0giIgAlcAwVfV2/IyuDIRAAHh//U6++9QyhsRH8eR108lM8WsqaqmHsiVQ/Ala/Als/RzxteDDQ21SLklTvgnjzoXUY4N3AsaYfiXQQAjkHkI64D+MZzkwvQd1iRaRAsAL3KWqrwApwG5V9fod80vzLgOIyA3ADQCZmZk9+Ni+69QxQ3j6W9O57vGlXPjgpzw47wTCPMLmyjo2VdaxuTKBTZUnU1yVj3ibmOLZyHTPOk6tWknSO7+Gd34NaeNg3Ndh3Ddg2CQQCfZpGWP6uUACobNfmp6M3papqhUiMhJ4V0RWA531u+z0mKo6H5gPzhVCDz63T5uSmcQL357JVY9+xoUPfLqvPNwjZKbEMDI1jq+MGcKotDhGpp3CsIRo5j68mGG6i6dPrCJy46vw0R/gw3sgMdO5ahj7dRgxDTxhQTwzY0x/FUgglAMj/JYzgIBnl1fVCvfvZhF5H5gMvAQkiki4e5XQo2MOFKOHDmbBjbN5s3A7wxOiGTUkjszkGCLCOr/Xf/eFxzP34cXcVZ3L7dd8F+p3wfrXYd0/4LP5zqB6sUPgrN/A8Zcd5bMxxvR3gfQyWgqMdnsFRQKXAQu72QcAEUkSkSj3fSowG1irzo2L94D2HklXA3/vaeUHgmEJ0Vw9K5uzJgxjVFpcl2EAMHNUClfNzOKxT7fw2ZZqiE2FKVfCFc/DLZvgwkcgbgi8fTv42o7iWRhjBoJuA8H9P/ibgDeBdcDzqlooIneKyLkAIjJVRMqBi4GHRKTQ3X0cUCAiK3EC4C6/3km3AjeLSBHOPYVHevPEBqpb54wlI2kQP3txJY0tfj/60fEw8SI4+adQt8PpsWSMMT3QbS+jvmSg9DI6XIs2VTH34cVcOzubO74x4cCVLQ3w+9GQeyGc+z/BqaAxpk8JtJeRDV3RD80clcLVM7N47JNilmyuOnBlZAyM+SqsWwjeluBU0BjTL1kg9FO3njOWzOQYbnlxFQ0t3gNX5l4IjTWw+f2g1M0Y0z9ZIPRTMZHh3H3RJEqrG7j7jfUHrhx1GkQnwpoXO9/ZGGM6YYHQj80YmcI1s7J5/NNiFvs3HYVHwvhz4YtXobUxeBU0xvQrFgj93M/mjCErJYafdWw6yr0QWupg41vBq5wxpl+xQOjnYiLDuftCp+nov1//Yv+K7JOch9RWW7ORMSYwFggDwHS36eivi0pYtMltOvKEwYRvOlcINkObMSYAFggDxL6mo5dWUt/sNh3lXgjeJmd4C2OM6YYFwgARExnOPRcdT3lNI79/y+11lDEVEkZYbyNjTEAsEAaQaTnJXDY1kycXlVBa1QAeD+ReAJvehYbqYFfPGNPHWSAMMD88fTRhHuG+dzY4BbkXOjOwrQtoPEJjTAizQBhg2kdPXbB8Kxt27HUmz0k51nobGWO6ZYEwAH3nlFHERobzx7c2ODOp5V7ozNm8d3uwq2aM6cMsEAag5NhI/u2kHN4o3M6q8t1OIKBQ+Eqwq2aM6cMsEAao60/MISkmgt+/tQHSxsDQidbbyBhzUAEFgojMEZH1IlIkIrd1sv5kEVkmIl4RucivPE9EFolIoYisEpFL/dY9LiJbRGSF+8rrnVMyAIOjI7jx1GP5cEOlM85R7gVQvhRqioNdNWNMH9VtIIhIGHA/cA4wHpgrIuM7bFYKXAM806G8AbhKVScAc4D7RCTRb/0tqprnvlYc4jmYLlw5M4uh8VH8/s31aO4FTmHhguBWyhjTZwVyhTANKFLVzaraAjwHnOe/gaoWq+oqwNehfIOqbnTfVwA7gbReqbnpVnREGD84fTQFJTW8vyPGeVBt9UvBrpYxpo8KJBDSgTK/5XK3rEdEZBoQCWzyK/6d25R0r4hE9fSYpnuX5I8gMzmGe95cj2/CBbBjNVSu735HY0zICSQQpJOyHk3ELCLDgSeBa1W1/Sri58BYYCqQDNzaxb43iEiBiBRUVlb25GMNEBHm4cdnjmbttj2845kFCKx5OdjVMsb0QYEEQjkwwm85A6gI9ANEJB54FfiVqi5uL1fVbepoBh7DaZr6ElWdr6r5qpqflmatTYfi3OPTOW5oHP/10W582Sc6vY20R5lujAkBgQTCUmC0iOSISCRwGRDQOAju9guAJ1T1hQ7rhrt/BTgfWNOTipvAhXmEn5w1hs276lk2+DSoKoLtq4JdLWNMH9NtIKiqF7gJeBNYBzyvqoUicqeInAsgIlNFpBy4GHhIRArd3S8BTgau6aR76dMishpYDaQCv+3VMzMHOGv8UI7PSODfN4xEPeGwxm4uG2MOJNqPmg7y8/O1oKAg2NXotz7euIt5jyzho4w/M6K1BH64yhkR1RgzoInI56qa39129msQQmYfm8LMkSk8XD0ZasucB9WMMcZlgRBCRISfnj2GlxryaPVEwxu32fSaxph9LBBCzAlZScwcl8VPfN9Ht6+CZy6BlvpgV8sY0wdYIISgn5w1hoVNk/mV/BBf6RKq/nIB9XV7g10tY0yQWSCEoHHD43n4qnyqc77GL/VGknYsoeDur3PtXz7ikY+3sLmyLthVNMYEgfUyCnEtXh+l//ozxy7+JR+Hz+CauhvxEk52SgynjhnC6eOGMHtUKh5PZw+sG2P6A+tlZAISGe7h2Dk3wTl3c6J3MSsnvcxvzx1LTmosz35WypWPfMaPn19Ba5uv+4MZY/q18GBXwPQR078N3iZi376deYNimHf1/TS1KQ9/uJk/vL2B2sZWHrjiBAZFhgW7psaYI8SuEMx+s38IX/klrHwGXr2Z6HAP3z99NP91wUQ+3FDJvEeWUNvQGuxaGmOOEAsEc6CTb4ETb4bPH4M3fg6qzJ2Wyf2XT2F1eS2Xzl/Ezj1Nwa6lMeYIsEAwBxKB02+HGTfCkgfgnV+DKudMHM6j10yltLqBCx/8lJIqe3bBmIHGAsF8mQic/Z+Qfz18fC/8YSy89C1O3Ps6L16WTl2TlwsfWMTaCnvK2ZiBxLqdmq75fLDqb1D0L9jyIdTvBKA1PpPX60bzsW8Ccy+Zx+TxY4JcUWPMwQTa7dQCwQRGFSq/cIJhy4f4tnyEp7kWgLr4Y4kb8xXImgkjZkBCj2dYNcYcQRYI5sjytbF78+csePlZRtUVMCtiI+Ftjc66hEzInA6ZM5yAGDIOPNZd1Zhg6dVAEJE5wJ+AMOAvqnpXh/UnA/cBk4DLVPVFv3VXA79yF3+rqn91y08AHgcGAa8BP9RuKmOB0PfUNXu54YkCPtu0gzkpu5g7vIITZD3R25ZC3XZno6gEGDHVCYjMmZB+AkQMCm7FjQkhvRYIIhIGbADOxJlfeSkwV1XX+m2TDcQDPwUWtgeCiCQDBUA+oMDnwAmqWiMinwE/BBbjBML/qOrrB6uLBULf1Oxt44WCcl5eVs6y0t14BGaPSmHeWDh10CaiKpZC6WKoXOfs4ImA9ClOOGTNdq4mohOCexLGDGCBBkIgTypPA4pUdbN74OeA84B9gaCqxe66juMbnA28rarV7vq3gTki8j4Qr6qL3PIncOZVPmggmL4pKjyMeTOymDcjiy276lmwfCsLlpfz7X82EhOZwpzca7jgrF8x85gwwsqXQOmnULIIFv0ffHIfIDA0F7JmOfchMmfB4KHBPi1jQk4ggZAOlPktlwPTAzx+Z/umu6/yTspNP5eTGsvNZx7Hj88YTUFJDS8vK+efq7bx8rKtDIuP5muTMpmWk0f+zF+SEtkGWwuccCj5BJY/CZ895BwoeSSMmA4jpjl/08bafQhjjrBAAqGzYS4DvRPd1b4BH1NEbgBuAMjMzAzwY02wiQhTs5OZmp3MHd+YwLtf7OTlZeU8uaiERz7eAsDI1Fjys5PIz7qc/K9+j5ykSGT7Kij5FMqWwMa3YeWzzgGj4iEjf39IpOdDdHy39aipb+G5pWV8fdJwRiTHHMlTNqbfCyQQyoERfssZQEWAxy8HTu2w7/tueUYgx1TV+cB8cO4hBPi5pg+JjgjjqxOH89WJw2lqbWPN1loKSmooKK7mrbU7eL7AuVhMiY1kSlYSU7O/xqlfuZbjhsRBzRYo+8wJiLLP4P27AAXxwJAJzr2I4cfD8DwYOn7fzeoWr48nFhV5F9JEAAARpklEQVTzP+9sZE+TlxcKylhw42wSYiKOyjnvqmtmd0Mrxw6JOyqfZ0xvCOSmcjjOTeXTga04N5UvV9XCTrZ9HPhnh5vKnwNT3E2W4dxUrhaRpcD3gSU4N5X/V1VfO1hd7KbywOPzKZt31VFQXMPS4ho+L6mmuKoBgFmjUrhudg6njR2yfz6GplooL9gfEttWQGONs07C0LQxVAw6jpe3pfDh3nSSRp3AmXmj+MWC1UzPSeGxa6cSEXZkH9B/Y812bnt5FXubvPzs7DF866SRNp+ECare7nb6VZxupWHAo6r6OxG5EyhQ1YUiMhVYACQBTcB2VZ3g7nsd8Av3UL9T1cfc8nz2dzt9Hfi+dTs1ADv3NPHy8q389dNittU2kZ0SwzWzsrkofwRxUR0ualWhtgy2raRyw2eUr11MRtN60qTW3UAgZRTlEdksKI9j2KjjuXjOGZA6ute7vtY3e/nNP9fy3NIyctPjyUiM4Y3C7Zw+dgh/uOR4EmMie/XzjAmUPZhm+r3WNh9vrNnOo59sYXnpbgZHhXPp1BFcPSv7gPsBO/c08fu31vPC5+UkDorg5jOPY+64SMJ3roZtq5yriMr1+Ko246HN3UsgKQtSx0Ca+0odA0nZEJvqjOfUAyvLdvOjv62guKqe75wyih+fcRwRYcITi0r47atrGTI4mv+7fDKTM5N67z/QALVzbxMpsVGE2VVVr7FAMAPKstIaHvukmNdWb0NVOXvCMK6cmcWykhr+/P4mWtt8XDMrm5tOG03CoM7vE7S1NPHrxxdSXbKGW6ZAlq8MKtdD1UZoa9m/YfggSBwBCSMgMdN5n5jlvE8YAXFDweM0O7X5lAc/2MS9b28gbXAUf7wkj5mjUg743JVlu7nx6WXs3NvEL746jmtmZSM9DJxQ4PMpD3ywiT+8tZ68EYn84ZI8clJjg12tAcECwQxIFbsbeXJxCc8sKaW20Zms5+wJQ/n5OePIDuDHo67Zy4V//pRttY288r3ZjEyLgzYv7C6BXRtgd+mBr9oyaKg68CCecIhNoyU6hbV7otjUMIiE1HRmTxrLoKThEJsGcWkQkwoxyRAxiNqGVn7ywgr+tW4n5+QO478vmkR89NG5wd0f1Da28pPnnf8+pxyXxvLSGlrafPz8nHFcOSPL7sEcJgsEM6A1tHh5s3A7GUkxTM1O7tG+ZdUNnH//J8QPiuCVQHoeNddBbbkbEKVQW05JWQlbSopJ0VpGxjQS01qNeLuYOCh8EAxKQmOS2NYcw4pqD62RiczMHc2QIcNhUCJEDXa61kbHO0N9RMc7yxHRPTq33tLY0sZvXl3LitLdzL/qBDKSjlyX3cKKWr771DIqdjfyq6+N4+pZ2ezY08ytL63igw2VzBqVwj0XH096og13cqgsEIw5iKXF1Vz+8GKm5STz+LXTAu55tHNPE3e9/gUvL9/K5MxE7rs0j6yUWOfmdksd1FdC/S6o2wkNu6ChGhqroaHG/VtN455KGmsridc6wr/0cH8HYZFOMEQNhqg4iIyDiBiIjN3/iohxyiNj9i+HRzt/I9r/DvpyWVhkp/dKinbu5XtPL2fDzr0MiggjOTaS526YcURC4YWCMn71yhqSYiK5/4rJnJC1P9xVleeWlvHbf67FI8K/f2M8F5+Q0S+a21rbfEe8N1tPWCAY040XCsq45cVVXDkji9+cn9vldvXNztXIguVb+aRoFwDfP2003z/tWMIP8R99dX0LNz+3jGUbS5k+3MO04eFMShWOS4IkTxM073G62DbvgaY9zt+WeufV2uC+b3BCqLUBuro66U54NIRFQXgUhEezxxvG1jofXolkxJAkwiKi+XxrPYRFMu3Y4cQMioHwSHefSCdUDngf4YxV1f4+rL083PnriYCwCJp9Hh74qIR/rKkkd0Qqd5x/PMmDY9314fu2wxNOWU0jP3lhJZ9tqeaMcUP4zwsmMmRwcK6cAvHa6m3c9tIqTj4ujT9ekkdkePCDwQLBmAD812vreOjDzdx53gSumpm9r9zb5uPjol28snwrbxbuoLG1jfTEQXxzcjoXTEl37j0cJp9PeexT50b56q21tHidq4X0xEFMzkxkSmYSJ2QlMW54fPc/Kr62/WHR2gCtTdDaCN5G5+++Mjc8WhvA2+K89zbT2tLI8s3b2VG9m6GxHo4fFk0UreBtorGxga1VtUSLl2GxHsJ9Lc5N+LYW8DYT+MAFh8gTjoZF0qIe6lsFr4QTNyiamOjofaGBJ3x/GHnC94dKx/f7ljuu72w5vMOxOyn3hDtDqnjCaVYPjy0q5dU1uxiaGEvp7hZOyEnljnOPJzoqstN9Dlg+glc+FgjGBKDNp3z7yQLeW1/J49dOJSkmkpeXbWXhygp21TUTHx3O1yYdwwVT0jkhM+mI3dxs9raxtmIPy0p3s6ykhmWlNWyrdf6vPyrcw6SMBLJSYkmJiyQ1NorUwZGkxEY5y3FRJMdGHnITxRfb9/C9p5exeVc9PzhtND84ffSXunyuLNvNvEeWkBQTybM3zNjfnq8KPq8TDL5WaGvdHxZtXr/3TvnKkkoe/mADHp+X62dlcPwxcc669n19Xr9l74HH9HmprWtgSdEO9jQ0kpUYwYiECBKjPUR52pA2r7P/vmN4/Y7Tyaut1QlSX+v+smASjxMOEtYhNNy/V/8DUkYd2qEtEIwJTF2zl4se+JQNO/biU4gIE04bO4RvTs7gK2PTiAoPzqB622obWVaym89LalhR5gREVV0LLW2d33dIjIkgLS6K8cfEMyUzicmZiYwbHt9lULS30f/HwkLiB0Xwp0vzmHVsapf1WVG2myv/soQk957CMT24yVtT38JDH27moQ83MWboYB6cd0JAvcI6423z8cD7m/jfd4v2/bdIGxzFpPQEctMTmJSRwMSMhJ43K6m6AeHdHxL7wqTjcvurjffXVfDYx0UMCofvnpTlhJzPCZuC4kqeXbSZEQmRfOvETGLD8fuM9uP6nPfadsBxD9hO2+C02w95FGALBGN6oLymgXveXM+0nGS+NnF4n32qWFXZ2+ylqq6FXXXNVNU1s6uuhaq6Fqrqm9lW28Sq8t3s2NMMQHSEh0npiUzOcpqgpmQmkTY4ir1NrfxiwRr+sbKCE49N5d5L80gbHNXt5/c0FEqq6nnk4y08X1BGU6uPi07I4Dfn5TIo8vBDtrGljbXb9rBmay2rymtZvXU3G3fW0f6TNiw+mokZCYwbNpjUwc5VVHJMJMlxzt+kw7iqAufe0u1/L+SlZeVMz0nmT5dNZljCl0Po3S928N2nlpGZHMNT/zadofE9C6pddc28snwr183OOeQrVAsEY0KUqlJR28Ty0hqWlexmWWkNhRW1tLY5/9Yzkgah6lyB3Hzmcdx46rE9+qFpD4XkOCcUhid8ORSWl9bw8EebeWPNdsI8wvl56Xzr5JEcN3Rwr51nZ+qbvazdtscJiPLdrNpay5Zd9XT1Mzc4OpyUWCccjkkYxPhj4slNTyD3mHhS4roOyHXb9nDTMwdvZvO3aFMV//bXpSTHRfL09TPITOm+x1ZpVQPzP9rECwXltLT5WHDjbPJGJHa7X2csEIwx+zS1tlFYUbsvICr3NnPL2WOYPjKl+507sby0hqse+eyAUPD5lHe/2Mn8DzfzWXE1g6PDuWJ6FtfOzu7x/xX3ptY2H7sbWqmub9n/amihxn+5voWS6nrKqhv37Tc8IZoJxySQmx6/7++w+GieXlLKnf9cS+KgCO67LI9Zo7puZvO3omw31zz2GVHhHp66fjqjuwjHNVtrefCDTby2ehvhHg/fnJzODaeMZNRhdGSwQDDGHFHL3FBIjYvk2tk5PLGomE2V9aQnDuK6E3O4dGongxH2cbUNrRRuq2VthdMUtaZiD5sq9zdDDY4OZ2+T1+1SejypB7mK6Mz67XuZ98gSvG0+nrhuOhMznKljVZVPiqp48INNfFy0i8FR4Vw+I5PrZuf0SphaIBhjjrj2UKhr9jJ+eDzfPmUkX504vE89lHW46pu9fLF9D2u27mFtxR7GHxN/WMNpFO+q54q/LGFPYyvzr8qnqr6Zhz7YzOqttaQNjuK62TlcMSOzV4c2sUAwxhwVG3fspbq+hWk5yf3iKeK+YFttI/P+soRNlfWAM3vgDSeP5JtT0o9Ir7ZAA6F/Xc8ZY/qcrtrCTdeGJwzi+W/P5L5/bWT2sSmcOX5YnxjuO6DrOhGZIyLrRaRIRG7rZH2UiPzNXb9ERLLd8itEZIXfyyciee66991jtq8b0psnZowxfVlKXBS/OT+XObnD+0QYQACBICJhwP3AOcB4YK6IjO+w2fVAjaoeC9wL/DeAqj6tqnmqmgdcCRSr6gq//a5oX6+qO3vhfIwxxhyiQK4QpgFFqrpZVVuA54DzOmxzHvBX9/2LwOny5cbEucCzh1NZY4wxR04ggZAOlPktl7tlnW6jql6gFujYwflSvhwIj7nNRf/eSYAYY4w5igIJhM5+qDt2TTroNiIyHWhQ1TV+669Q1YnASe7ryk4/XOQGESkQkYLKysoAqmuMMeZQBBII5cAIv+UMoKKrbUQkHEgAqv3WX0aHqwNV3er+3Qs8g9M09SWqOl9V81U1Py0tLYDqGmOMORSBBMJSYLSI5IhIJM6P+8IO2ywErnbfXwS8q+4DDiLiAS7GufeAWxYuIqnu+wjg68AajDHGBE23zyGoqldEbgLeBMKAR1W1UETuBApUdSHwCPCkiBThXBlc5neIk4FyVd3sVxYFvOmGQRjwL+DhXjkjY4wxh8SeVDbGmAFuQA5dISKVQMkh7p4K7OrF6gSDnUPfYOfQNwyEc4Cjcx5ZqtrtTdh+FQiHQ0QKAknIvszOoW+wc+gbBsI5QN86j4EzJKExxpjDYoFgjDEGCK1AmB/sCvQCO4e+wc6hbxgI5wB96DxC5h6CMcaYgwulKwRjjDEHERKB0N18Dv2BiBSLyGp3MMB+8TCGiDwqIjtFZI1fWbKIvC0iG92/ScGsY3e6OIf/EJGtfnN5fDWYdeyOiIwQkfdEZJ2IFIrID93yfvNdHOQc+s13ISLRIvKZiKx0z+HXbnmOO4/MRndemcig1XGgNxm58zlsAM7EGXNpKTBXVdcGtWI9JCLFQL6q9pt+1yJyMlAHPKGquW7Z3UC1qt7lhnOSqt4azHoeTBfn8B9Anar+Pph1C5SIDAeGq+oyERkMfA6cD1xDP/kuDnIOl9BPvgt3ROdYVa1zR2n4GPghcDPwsqo+JyIPAitV9YFg1DEUrhACmc/BHAGq+iEHDnIIB86d8Vecf9R9Vhfn0K+o6jZVXea+3wuswxmyvt98Fwc5h35DHXXuYoT7UuA0nHlkIMjfQygEQiDzOfQHCrwlIp+LyA3BrsxhGKqq28D5Rw7016lTbxKRVW6TUp9taunInd52MrCEfvpddDgH6EffhYiEicgKYCfwNrAJ2O3OIwNB/n0KhUAIZD6H/mC2qk7Bmcr0e25ThgmOB4BRQB6wDfhDcKsTGBGJA14CfqSqe4Jdn0PRyTn0q+9CVdvcKYUzcFovxnW22dGt1X6hEAiBzOfQ56lqhft3J7CALuaP6Ad2uO3B7e3C/W4ubVXd4f7D9uGM0tvnvwu3zfol4GlVfdkt7lffRWfn0B+/CwBV3Q28D8wAEt15ZCDIv0+hEAiBzOfQp4lIrHsjDRGJBc6i/84f4T93xtXA34NYl0PS/iPq+iZ9/Ltwb2Y+AqxT1T/6reo330VX59CfvgsRSRORRPf9IOAMnHsh7+HMIwNB/h4GfC8jALcr2n3sn8/hd0GuUo+IyEicqwJw5rB4pj+cg4g8C5yKM5rjDuAO4BXgeSATKAUuVtU+e9O2i3M4FaeJQoFi4NvtbfF9kYicCHwErAZ8bvEvcNrg+8V3cZBzmEs/+S5EZBLOTeMwnP8Zf15V73T/fT8HJAPLgXmq2hyUOoZCIBhjjOleKDQZGWOMCYAFgjHGGMACwRhjjMsCwRhjDGCBYIwxxmWBYIwxBrBAMMYY47JAMMYYA8D/A1PC85Cko0HuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(treerr)\n",
    "plt.plot(everr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3288.0</td>\n",
       "      <td>3288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          err\n",
       "count  3288.0  3288.000000\n",
       "mean      0.0     0.087218\n",
       "std       0.0     0.029828\n",
       "min       0.0     0.000725\n",
       "25%       0.0     0.078680\n",
       "50%       0.0     0.093318\n",
       "75%       0.0     0.104880\n",
       "max       0.0     0.198570"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=np.array(out)\n",
    "dfout=pd.DataFrame(data={\"label\":out[:,0],\"err\":out[:,1]})\n",
    "dfout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11704557369297244"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.describe().loc['mean','err']+dfout.describe().loc['std','err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh2 of err = mean+std =  0.11704557369297244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012092174309833448"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh2=dfout.describe().loc['mean','err']+dfout.describe().loc['std','err']\n",
    "print(\"thresh2 of err = mean+std = \",thresh2)\n",
    "dfout['pred2']=0\n",
    "dfout.loc[dfout['err']>thresh2,'pred2']=1\n",
    "dfout.pred2.sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "#Defining Prediction from loss\n",
    "print(thresh)\n",
    "dfout['pred']=0\n",
    "dfout.loc[dfout['err']>thresh,'pred']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>err</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3288.0</td>\n",
       "      <td>3288.000000</td>\n",
       "      <td>3288.000000</td>\n",
       "      <td>3288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087218</td>\n",
       "      <td>0.080596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.272255</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          err        pred2    pred\n",
       "count  3288.0  3288.000000  3288.000000  3288.0\n",
       "mean      0.0     0.087218     0.080596     0.0\n",
       "std       0.0     0.029828     0.272255     0.0\n",
       "min       0.0     0.000725     0.000000     0.0\n",
       "25%       0.0     0.078680     0.000000     0.0\n",
       "50%       0.0     0.093318     0.000000     0.0\n",
       "75%       0.0     0.104880     0.000000     0.0\n",
       "max       0.0     0.198570     1.000000     0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
