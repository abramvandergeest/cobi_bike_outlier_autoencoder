{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=\"cobi_state_data.csv\"\n",
    "df=pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsspeedmax=10.\n",
    "userPowermax=100.\n",
    "ridingDurationmax=500.\n",
    "ridingDistancemax=2000.\n",
    "ascentmax=15.\n",
    "caloriesmax=50.\n",
    "heartratemax=150.\n",
    "cadencemax=90.\n",
    "averageSpeedmax=8.\n",
    "\n",
    "df['rsspeed']=df['rsspeed']/rsspeedmax\n",
    "df['userPower']=df['userPower']/userPowermax\n",
    "df['ridingDuration']=df['ridingDuration']/ridingDurationmax\n",
    "df['ridingDistance']=df['ridingDistance']/ridingDistancemax\n",
    "df['ascent']=df['ascent']/ascentmax\n",
    "df['calories']=df['calories']/caloriesmax\n",
    "df['heartRate']=df['heartRate']/heartratemax\n",
    "df['cadence']=df['cadence']/cadencemax\n",
    "df['averageSpeed']=df['averageSpeed']/averageSpeedmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rsspeed',\n",
       " 'userPower',\n",
       " 'ridingDuration',\n",
       " 'ridingDistance',\n",
       " 'ascent',\n",
       " 'calories',\n",
       " 'heartRate',\n",
       " 'cadence',\n",
       " 'averageSpeed']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=[col for col in df.columns ]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dftrain,dftest=train_test_split(df,test_size=0.15)\n",
    "dftest['Class']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numinps= len(cols)\n",
    "numinps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Test/Train split for train and eval data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain2,dfeval=train_test_split(dftrain,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Building the autoencoder</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So the Threshold is determined below and then put into the model as hardwired (not used to determine the threshold - no loops here) so that we can export the model at the same time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedim=14\n",
    "hiddim=encodedim//2\n",
    "learnrate=0.001\n",
    "droprate=0.2\n",
    "thresh=0.15 #picked as just above max value to detect anything outside the norm\n",
    "threshold=tf.constant(thresh)\n",
    "inputs=tf.placeholder(tf.float32, shape=(None,numinps),name=\"inputs\")\n",
    "#mode=tf.placeholder(tf.string, name=\"mode\")\n",
    "\n",
    "dense0 = tf.layers.dense(inputs=inputs, units=encodedim, activation=tf.nn.tanh)\n",
    "dropout0 = tf.layers.dropout(inputs=dense0, rate=droprate)\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=dropout0, units=hiddim, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=droprate)\n",
    "\n",
    "dense2 = tf.layers.dense(inputs=dropout1, units=hiddim, activation=tf.nn.tanh)\n",
    "dropout2 = tf.layers.dropout(inputs=dense2, rate=droprate)\n",
    "\n",
    "dense3 = tf.layers.dense(inputs=dropout2, units=numinps, activation=tf.nn.relu)\n",
    "dropout3 = tf.layers.dropout(inputs=dense3, rate=droprate)\n",
    "\n",
    "loss=tf.losses.mean_squared_error(labels=inputs,predictions=dropout3)\n",
    "Yout=tf.cast(tf.math.greater(loss,0.15), tf.int32)\n",
    "trainstep=tf.train.AdamOptimizer(learning_rate=learnrate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Training Autoencoder and then exporting saved_model format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0 0 0.28222603\n",
      "evalu:  0 0 [0.27617252]\n",
      "train:  0 1 0.27981907\n",
      "train:  0 2 0.2728107\n",
      "train:  0 3 0.26185098\n",
      "train:  0 4 0.2674988\n",
      "train:  0 5 0.25449082\n",
      "train:  0 6 0.2588505\n",
      "train:  0 7 0.25489497\n",
      "train:  0 8 0.23951471\n",
      "train:  0 9 0.23507762\n",
      "train:  0 10 0.23550819\n",
      "train:  0 11 0.23188327\n",
      "train:  0 12 0.2229608\n",
      "train:  0 13 0.21053942\n",
      "train:  0 14 0.21290024\n",
      "train:  0 15 0.21012427\n",
      "train:  0 16 0.19186324\n",
      "train:  0 17 0.18269412\n",
      "train:  0 18 0.19180523\n",
      "train:  0 19 0.18047455\n",
      "train:  0 20 0.17494008\n",
      "evalu:  0 20 [0.16911955]\n",
      "train:  0 21 0.17408651\n",
      "train:  0 22 0.16656277\n",
      "train:  0 23 0.15786509\n",
      "train:  0 24 0.15482333\n",
      "train:  0 25 0.15003018\n",
      "train:  0 26 0.13755377\n",
      "train:  0 27 0.12789214\n",
      "train:  0 28 0.12814292\n",
      "train:  0 29 0.12426077\n",
      "train:  0 30 0.11562147\n",
      "train:  0 31 0.115440056\n",
      "train:  0 32 0.110404395\n",
      "train:  0 33 0.102971956\n",
      "train:  0 34 0.09373724\n",
      "train:  0 35 0.09280446\n",
      "train:  0 36 0.090830944\n",
      "train:  0 37 0.089277774\n",
      "train:  0 38 0.082571484\n",
      "train:  0 39 0.07847621\n",
      "train:  0 40 0.07810815\n",
      "evalu:  0 40 [0.07571979]\n",
      "train:  0 41 0.075422466\n",
      "train:  0 42 0.07591413\n",
      "train:  0 43 0.07188595\n",
      "train:  0 44 0.06778722\n",
      "train:  0 45 0.069608755\n",
      "train:  0 46 0.066186555\n",
      "train:  0 47 0.06971348\n",
      "train:  0 48 0.065176025\n",
      "train:  0 49 0.061892632\n",
      "train:  0 50 0.06299286\n",
      "train:  0 51 0.060109977\n",
      "train:  0 52 0.059195433\n",
      "train:  0 53 0.06078428\n",
      "train:  0 54 0.055255134\n",
      "train:  0 55 0.052759897\n",
      "train:  0 56 0.054370236\n",
      "train:  0 57 0.053789344\n",
      "train:  0 58 0.050867647\n",
      "train:  0 59 0.054780446\n",
      "train:  0 60 0.05103829\n",
      "evalu:  0 60 [0.05064643]\n",
      "train:  0 61 0.04950255\n",
      "train:  0 62 0.051752735\n",
      "train:  0 63 0.052397043\n",
      "train:  0 64 0.047574986\n",
      "train:  0 65 0.04766148\n",
      "train:  0 66 0.050595492\n",
      "train:  0 67 0.0503803\n",
      "train:  0 68 0.05138095\n",
      "train:  0 69 0.04904672\n",
      "train:  0 70 0.04254634\n",
      "train:  0 71 0.04791321\n",
      "train:  0 72 0.04523606\n",
      "train:  0 73 0.049268566\n",
      "train:  0 74 0.047149528\n",
      "train:  0 75 0.04604249\n",
      "train:  0 76 0.046854913\n",
      "train:  0 77 0.04790641\n",
      "train:  0 78 0.04622682\n",
      "train:  0 79 0.04620075\n",
      "train:  0 80 0.0408587\n",
      "evalu:  0 80 [0.045028478]\n",
      "train:  0 81 0.046821643\n",
      "train:  0 82 0.04653606\n",
      "train:  0 83 0.04317243\n",
      "train:  0 84 0.042964637\n",
      "train:  0 85 0.042492703\n",
      "train:  0 86 0.044062838\n",
      "train:  0 87 0.04295946\n",
      "train:  0 88 0.042303648\n",
      "train:  0 89 0.045873124\n",
      "train:  0 90 0.04733467\n",
      "train:  0 91 0.047552004\n",
      "train:  0 92 0.045798708\n",
      "train:  0 93 0.042770687\n",
      "train:  0 94 0.045435052\n",
      "train:  0 95 0.042033214\n",
      "train:  0 96 0.04360694\n",
      "train:  0 97 0.04570835\n",
      "train:  0 98 0.044224482\n",
      "train:  0 99 0.040801574\n",
      "train:  0 100 0.04432464\n",
      "evalu:  0 100 [0.04260145]\n",
      "train:  0 101 0.040033136\n",
      "train:  0 102 0.04232211\n",
      "train:  0 103 0.041700915\n",
      "train:  0 104 0.043351416\n",
      "train:  0 105 0.037652697\n",
      "train:  0 106 0.040008206\n",
      "train:  0 107 0.043338012\n",
      "train:  0 108 0.039964028\n",
      "train:  0 109 0.044248648\n",
      "train:  0 110 0.040703762\n",
      "train:  0 111 0.041598875\n",
      "train:  0 112 0.040860817\n",
      "train:  0 113 0.04302259\n",
      "train:  0 114 0.040038235\n",
      "train:  0 115 0.03864685\n",
      "train:  0 116 0.039638806\n",
      "train:  0 117 0.04305151\n",
      "train:  0 118 0.04098117\n",
      "train:  0 119 0.04356737\n",
      "train:  0 120 0.041078202\n",
      "evalu:  0 120 [0.040731218]\n",
      "train:  0 121 0.043462474\n",
      "train:  0 122 0.042104788\n",
      "train:  0 123 0.042187948\n",
      "train:  0 124 0.043031126\n",
      "train:  0 125 0.038110405\n",
      "train:  0 126 0.040779326\n",
      "train:  0 127 0.03697505\n",
      "train:  0 128 0.03848571\n",
      "train:  0 129 0.039457835\n",
      "train:  0 130 0.04016342\n",
      "train:  0 131 0.040766265\n",
      "train:  0 132 0.04044655\n",
      "train:  0 133 0.04026282\n",
      "train:  0 134 0.040568713\n",
      "train:  0 135 0.035912637\n",
      "train:  0 136 0.039375696\n",
      "train:  0 137 0.03762618\n",
      "train:  0 138 0.04011547\n",
      "train:  0 139 0.042522285\n",
      "train:  0 140 0.038731586\n",
      "evalu:  0 140 [0.038982846]\n",
      "train:  0 141 0.037260752\n",
      "train:  0 142 0.037684742\n",
      "train:  0 143 0.03808881\n",
      "train:  0 144 0.040309817\n",
      "train:  0 145 0.03936525\n",
      "train:  0 146 0.040426534\n",
      "train:  0 147 0.037252296\n",
      "train:  0 148 0.037794188\n",
      "train:  0 149 0.037604474\n",
      "train:  0 150 0.03382301\n",
      "train:  0 151 0.040583547\n",
      "train:  0 152 0.038084336\n",
      "train:  0 153 0.037278842\n",
      "train:  0 154 0.038179826\n",
      "train:  0 155 0.03740264\n",
      "train:  0 156 0.03689605\n",
      "train:  0 157 0.03715817\n",
      "train:  1 0 0.039285142\n",
      "evalu:  1 0 [0.03752872]\n",
      "train:  1 1 0.041567728\n",
      "train:  1 2 0.042264767\n",
      "train:  1 3 0.04085675\n",
      "train:  1 4 0.035605207\n",
      "train:  1 5 0.03803283\n",
      "train:  1 6 0.036038388\n",
      "train:  1 7 0.038037784\n",
      "train:  1 8 0.038087048\n",
      "train:  1 9 0.037928026\n",
      "train:  1 10 0.036006097\n",
      "train:  1 11 0.035040215\n",
      "train:  1 12 0.038258847\n",
      "train:  1 13 0.038001463\n",
      "train:  1 14 0.036029026\n",
      "train:  1 15 0.039161507\n",
      "train:  1 16 0.033444345\n",
      "train:  1 17 0.035900906\n",
      "train:  1 18 0.037910502\n",
      "train:  1 19 0.038668144\n",
      "train:  1 20 0.0374669\n",
      "evalu:  1 20 [0.035948943]\n",
      "train:  1 21 0.036181062\n",
      "train:  1 22 0.036634568\n",
      "train:  1 23 0.037832346\n",
      "train:  1 24 0.035462335\n",
      "train:  1 25 0.036463134\n",
      "train:  1 26 0.03420204\n",
      "train:  1 27 0.033270262\n",
      "train:  1 28 0.03775491\n",
      "train:  1 29 0.03889407\n",
      "train:  1 30 0.034732334\n",
      "train:  1 31 0.03871291\n",
      "train:  1 32 0.035971027\n",
      "train:  1 33 0.03523679\n",
      "train:  1 34 0.030922621\n",
      "train:  1 35 0.03472746\n",
      "train:  1 36 0.035001483\n",
      "train:  1 37 0.035708643\n",
      "train:  1 38 0.034013495\n",
      "train:  1 39 0.03304087\n",
      "train:  1 40 0.034892093\n",
      "evalu:  1 40 [0.034191832]\n",
      "train:  1 41 0.035413273\n",
      "train:  1 42 0.034268916\n",
      "train:  1 43 0.03319779\n",
      "train:  1 44 0.032948494\n",
      "train:  1 45 0.035191625\n",
      "train:  1 46 0.034644518\n",
      "train:  1 47 0.036665097\n",
      "train:  1 48 0.035135094\n",
      "train:  1 49 0.032140534\n",
      "train:  1 50 0.03355659\n",
      "train:  1 51 0.033961847\n",
      "train:  1 52 0.029040147\n",
      "train:  1 53 0.032401133\n",
      "train:  1 54 0.030598683\n",
      "train:  1 55 0.03130165\n",
      "train:  1 56 0.030870482\n",
      "train:  1 57 0.030041581\n",
      "train:  1 58 0.029512415\n",
      "train:  1 59 0.030511934\n",
      "train:  1 60 0.028430672\n",
      "evalu:  1 60 [0.028814694]\n",
      "train:  1 61 0.026819952\n",
      "train:  1 62 0.02927838\n",
      "train:  1 63 0.029853122\n",
      "train:  1 64 0.02550508\n",
      "train:  1 65 0.027683746\n",
      "train:  1 66 0.028148178\n",
      "train:  1 67 0.026684117\n",
      "train:  1 68 0.02602748\n",
      "train:  1 69 0.026634991\n",
      "train:  1 70 0.022320207\n",
      "train:  1 71 0.02516159\n",
      "train:  1 72 0.024008468\n",
      "train:  1 73 0.027007287\n",
      "train:  1 74 0.024270946\n",
      "train:  1 75 0.025562542\n",
      "train:  1 76 0.024606986\n",
      "train:  1 77 0.026178202\n",
      "train:  1 78 0.02200803\n",
      "train:  1 79 0.021832911\n",
      "train:  1 80 0.019574039\n",
      "evalu:  1 80 [0.022601837]\n",
      "train:  1 81 0.025756542\n",
      "train:  1 82 0.021554824\n",
      "train:  1 83 0.021874249\n",
      "train:  1 84 0.021784207\n",
      "train:  1 85 0.019964637\n",
      "train:  1 86 0.022092663\n",
      "train:  1 87 0.02047882\n",
      "train:  1 88 0.022792734\n",
      "train:  1 89 0.022521788\n",
      "train:  1 90 0.02176732\n",
      "train:  1 91 0.024612058\n",
      "train:  1 92 0.02242136\n",
      "train:  1 93 0.020195711\n",
      "train:  1 94 0.02118932\n",
      "train:  1 95 0.021063758\n",
      "train:  1 96 0.021925159\n",
      "train:  1 97 0.024142692\n",
      "train:  1 98 0.022544077\n",
      "train:  1 99 0.019548386\n",
      "train:  1 100 0.020340716\n",
      "evalu:  1 100 [0.020818932]\n",
      "train:  1 101 0.020901227\n",
      "train:  1 102 0.02091738\n",
      "train:  1 103 0.020268332\n",
      "train:  1 104 0.022572543\n",
      "train:  1 105 0.017015476\n",
      "train:  1 106 0.01902551\n",
      "train:  1 107 0.02113314\n",
      "train:  1 108 0.020829387\n",
      "train:  1 109 0.0218079\n",
      "train:  1 110 0.018696621\n",
      "train:  1 111 0.018649338\n",
      "train:  1 112 0.02089766\n",
      "train:  1 113 0.023101173\n",
      "train:  1 114 0.02006894\n",
      "train:  1 115 0.01913201\n",
      "train:  1 116 0.019331336\n",
      "train:  1 117 0.021967083\n",
      "train:  1 118 0.019449612\n",
      "train:  1 119 0.022734562\n",
      "train:  1 120 0.020888899\n",
      "evalu:  1 120 [0.019670062]\n",
      "train:  1 121 0.020835135\n",
      "train:  1 122 0.021551656\n",
      "train:  1 123 0.021474525\n",
      "train:  1 124 0.021541646\n",
      "train:  1 125 0.017469086\n",
      "train:  1 126 0.019186262\n",
      "train:  1 127 0.017627573\n",
      "train:  1 128 0.018387752\n",
      "train:  1 129 0.01945903\n",
      "train:  1 130 0.017628705\n",
      "train:  1 131 0.01939227\n",
      "train:  1 132 0.02010634\n",
      "train:  1 133 0.019876705\n",
      "train:  1 134 0.020742552\n",
      "train:  1 135 0.0155364\n",
      "train:  1 136 0.020136228\n",
      "train:  1 137 0.017791927\n",
      "train:  1 138 0.018671472\n",
      "train:  1 139 0.020983526\n",
      "train:  1 140 0.01736345\n",
      "evalu:  1 140 [0.018668825]\n",
      "train:  1 141 0.017211944\n",
      "train:  1 142 0.018117921\n",
      "train:  1 143 0.018498002\n",
      "train:  1 144 0.02043315\n",
      "train:  1 145 0.019200642\n",
      "train:  1 146 0.02098242\n",
      "train:  1 147 0.01713027\n",
      "train:  1 148 0.018040128\n",
      "train:  1 149 0.020291561\n",
      "train:  1 150 0.015265856\n",
      "train:  1 151 0.019273778\n",
      "train:  1 152 0.020238813\n",
      "train:  1 153 0.0165041\n",
      "train:  1 154 0.019186383\n",
      "train:  1 155 0.017846847\n",
      "train:  1 156 0.018281318\n",
      "train:  1 157 0.01722185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  2 0 0.018751033\n",
      "evalu:  2 0 [0.017854804]\n",
      "train:  2 1 0.019299421\n",
      "train:  2 2 0.018682117\n",
      "train:  2 3 0.020691007\n",
      "train:  2 4 0.016721394\n",
      "train:  2 5 0.018788125\n",
      "train:  2 6 0.01642155\n",
      "train:  2 7 0.016533727\n",
      "train:  2 8 0.019267486\n",
      "train:  2 9 0.01943687\n",
      "train:  2 10 0.017053578\n",
      "train:  2 11 0.0158842\n",
      "train:  2 12 0.016729573\n",
      "train:  2 13 0.01921149\n",
      "train:  2 14 0.016238991\n",
      "train:  2 15 0.0181457\n",
      "train:  2 16 0.0163196\n",
      "train:  2 17 0.018049074\n",
      "train:  2 18 0.017524753\n",
      "train:  2 19 0.020719385\n",
      "train:  2 20 0.01706392\n",
      "evalu:  2 20 [0.016971007]\n",
      "train:  2 21 0.015943157\n",
      "train:  2 22 0.015871897\n",
      "train:  2 23 0.018961368\n",
      "train:  2 24 0.01589475\n",
      "train:  2 25 0.016765773\n",
      "train:  2 26 0.015727911\n",
      "train:  2 27 0.016875202\n",
      "train:  2 28 0.018107248\n",
      "train:  2 29 0.018536787\n",
      "train:  2 30 0.015247074\n",
      "train:  2 31 0.018358467\n",
      "train:  2 32 0.015185305\n",
      "train:  2 33 0.017137803\n",
      "train:  2 34 0.015638644\n",
      "train:  2 35 0.017542256\n",
      "train:  2 36 0.015552823\n",
      "train:  2 37 0.016040161\n",
      "train:  2 38 0.016070131\n",
      "train:  2 39 0.015279347\n",
      "train:  2 40 0.018093351\n",
      "evalu:  2 40 [0.016158096]\n",
      "train:  2 41 0.01739281\n",
      "train:  2 42 0.017053882\n",
      "train:  2 43 0.015539557\n",
      "train:  2 44 0.015478878\n",
      "train:  2 45 0.017251175\n",
      "train:  2 46 0.014966405\n",
      "train:  2 47 0.018910503\n",
      "train:  2 48 0.01667835\n",
      "train:  2 49 0.0150431255\n",
      "train:  2 50 0.014571754\n",
      "train:  2 51 0.017825808\n",
      "train:  2 52 0.012485689\n",
      "train:  2 53 0.015844248\n",
      "train:  2 54 0.017203463\n",
      "train:  2 55 0.016679514\n",
      "train:  2 56 0.015024707\n",
      "train:  2 57 0.016604796\n",
      "train:  2 58 0.015458269\n",
      "train:  2 59 0.016889999\n",
      "train:  2 60 0.01566891\n",
      "evalu:  2 60 [0.01533901]\n",
      "train:  2 61 0.013632354\n",
      "train:  2 62 0.015459192\n",
      "train:  2 63 0.01665004\n",
      "train:  2 64 0.01422838\n",
      "train:  2 65 0.016623741\n",
      "train:  2 66 0.016869834\n",
      "train:  2 67 0.0159195\n",
      "train:  2 68 0.015547868\n",
      "train:  2 69 0.015751248\n",
      "train:  2 70 0.013334212\n",
      "train:  2 71 0.015058439\n",
      "train:  2 72 0.014227898\n",
      "train:  2 73 0.017115569\n",
      "train:  2 74 0.015394683\n",
      "train:  2 75 0.015988173\n",
      "train:  2 76 0.01543677\n",
      "train:  2 77 0.016086452\n",
      "train:  2 78 0.013707408\n",
      "train:  2 79 0.014293468\n",
      "train:  2 80 0.013224108\n",
      "evalu:  2 80 [0.014557106]\n",
      "train:  2 81 0.016638909\n",
      "train:  2 82 0.01417558\n",
      "train:  2 83 0.013885095\n",
      "train:  2 84 0.013867283\n",
      "train:  2 85 0.013032356\n",
      "train:  2 86 0.0142816175\n",
      "train:  2 87 0.013594041\n",
      "train:  2 88 0.015437178\n",
      "train:  2 89 0.015046021\n",
      "train:  2 90 0.014245331\n",
      "train:  2 91 0.016090885\n",
      "train:  2 92 0.014297711\n",
      "train:  2 93 0.0127477115\n",
      "train:  2 94 0.013319807\n",
      "train:  2 95 0.0136403125\n",
      "train:  2 96 0.015343106\n",
      "train:  2 97 0.014972272\n",
      "train:  2 98 0.014926417\n",
      "train:  2 99 0.013267597\n",
      "train:  2 100 0.013353907\n",
      "evalu:  2 100 [0.013815295]\n",
      "train:  2 101 0.013105763\n",
      "train:  2 102 0.013706725\n",
      "train:  2 103 0.013812137\n",
      "train:  2 104 0.015133965\n",
      "train:  2 105 0.010839999\n",
      "train:  2 106 0.012147054\n",
      "train:  2 107 0.014214788\n",
      "train:  2 108 0.013785833\n",
      "train:  2 109 0.014828511\n",
      "train:  2 110 0.012095315\n",
      "train:  2 111 0.01282636\n",
      "train:  2 112 0.013661539\n",
      "train:  2 113 0.01501701\n",
      "train:  2 114 0.013390805\n",
      "train:  2 115 0.01323046\n",
      "train:  2 116 0.013347832\n",
      "train:  2 117 0.014619609\n",
      "train:  2 118 0.012779687\n",
      "train:  2 119 0.015372205\n",
      "train:  2 120 0.014148315\n",
      "evalu:  2 120 [0.01310917]\n",
      "train:  2 121 0.013320555\n",
      "train:  2 122 0.014160951\n",
      "train:  2 123 0.01428389\n",
      "train:  2 124 0.014141071\n",
      "train:  2 125 0.012126959\n",
      "train:  2 126 0.0122491345\n",
      "train:  2 127 0.011488586\n",
      "train:  2 128 0.012873993\n",
      "train:  2 129 0.013085611\n",
      "train:  2 130 0.011560172\n",
      "train:  2 131 0.013013431\n",
      "train:  2 132 0.013122121\n",
      "train:  2 133 0.012981874\n",
      "train:  2 134 0.013790095\n",
      "train:  2 135 0.010337984\n",
      "train:  2 136 0.013683035\n",
      "train:  2 137 0.011708818\n",
      "train:  2 138 0.0127244815\n",
      "train:  2 139 0.014482013\n",
      "train:  2 140 0.012308123\n",
      "evalu:  2 140 [0.012426207]\n",
      "train:  2 141 0.01182396\n",
      "train:  2 142 0.0119112795\n",
      "train:  2 143 0.012554721\n",
      "train:  2 144 0.013646273\n",
      "train:  2 145 0.012481426\n",
      "train:  2 146 0.01418325\n",
      "train:  2 147 0.011538773\n",
      "train:  2 148 0.011722287\n",
      "train:  2 149 0.013457237\n",
      "train:  2 150 0.010213027\n",
      "train:  2 151 0.012274586\n",
      "train:  2 152 0.013272357\n",
      "train:  2 153 0.010898755\n",
      "train:  2 154 0.012638128\n",
      "train:  2 155 0.012411292\n",
      "train:  2 156 0.012121682\n",
      "train:  2 157 0.011741632\n",
      "train:  3 0 0.012322269\n",
      "evalu:  3 0 [0.01185343]\n",
      "train:  3 1 0.012923701\n",
      "train:  3 2 0.01238291\n",
      "train:  3 3 0.013208111\n",
      "train:  3 4 0.011379659\n",
      "train:  3 5 0.012409021\n",
      "train:  3 6 0.01097976\n",
      "train:  3 7 0.011382246\n",
      "train:  3 8 0.0119848065\n",
      "train:  3 9 0.013042642\n",
      "train:  3 10 0.011150212\n",
      "train:  3 11 0.010903184\n",
      "train:  3 12 0.011105556\n",
      "train:  3 13 0.013028047\n",
      "train:  3 14 0.010260813\n",
      "train:  3 15 0.012146579\n",
      "train:  3 16 0.011128457\n",
      "train:  3 17 0.011915243\n",
      "train:  3 18 0.0123800915\n",
      "train:  3 19 0.014034208\n",
      "train:  3 20 0.011879952\n",
      "evalu:  3 20 [0.011247002]\n",
      "train:  3 21 0.010803746\n",
      "train:  3 22 0.01071519\n",
      "train:  3 23 0.012540656\n",
      "train:  3 24 0.010896882\n",
      "train:  3 25 0.011273235\n",
      "train:  3 26 0.009820422\n",
      "train:  3 27 0.011777614\n",
      "train:  3 28 0.012091386\n",
      "train:  3 29 0.012030533\n",
      "train:  3 30 0.010463724\n",
      "train:  3 31 0.012228419\n",
      "train:  3 32 0.010083481\n",
      "train:  3 33 0.011618639\n",
      "train:  3 34 0.010454983\n",
      "train:  3 35 0.011833992\n",
      "train:  3 36 0.010355558\n",
      "train:  3 37 0.011012084\n",
      "train:  3 38 0.010653808\n",
      "train:  3 39 0.010110072\n",
      "train:  3 40 0.012593685\n",
      "evalu:  3 40 [0.01069909]\n",
      "train:  3 41 0.0109166885\n",
      "train:  3 42 0.011656113\n",
      "train:  3 43 0.0104845185\n",
      "train:  3 44 0.010385318\n",
      "train:  3 45 0.011451032\n",
      "train:  3 46 0.009305475\n",
      "train:  3 47 0.013354235\n",
      "train:  3 48 0.010773777\n",
      "train:  3 49 0.010298419\n",
      "train:  3 50 0.009837506\n",
      "train:  3 51 0.0120110465\n",
      "train:  3 52 0.008430002\n",
      "train:  3 53 0.010570482\n",
      "train:  3 54 0.011640142\n",
      "train:  3 55 0.010744472\n",
      "train:  3 56 0.009875585\n",
      "train:  3 57 0.010964788\n",
      "train:  3 58 0.009588878\n",
      "train:  3 59 0.011110252\n",
      "train:  3 60 0.011094044\n",
      "evalu:  3 60 [0.010152592]\n",
      "train:  3 61 0.008885385\n",
      "train:  3 62 0.010173512\n",
      "train:  3 63 0.011228885\n",
      "train:  3 64 0.009469984\n",
      "train:  3 65 0.011036672\n",
      "train:  3 66 0.011160378\n",
      "train:  3 67 0.010596297\n",
      "train:  3 68 0.011002381\n",
      "train:  3 69 0.009972421\n",
      "train:  3 70 0.008645413\n",
      "train:  3 71 0.009670141\n",
      "train:  3 72 0.009084361\n",
      "train:  3 73 0.011194661\n",
      "train:  3 74 0.010194953\n",
      "train:  3 75 0.010470395\n",
      "train:  3 76 0.009997891\n",
      "train:  3 77 0.010370903\n",
      "train:  3 78 0.0090934755\n",
      "train:  3 79 0.009965402\n",
      "train:  3 80 0.00915419\n",
      "evalu:  3 80 [0.009653876]\n",
      "train:  3 81 0.010780241\n",
      "train:  3 82 0.00943669\n",
      "train:  3 83 0.009006426\n",
      "train:  3 84 0.009092011\n",
      "train:  3 85 0.008634013\n",
      "train:  3 86 0.009442723\n",
      "train:  3 87 0.009053908\n",
      "train:  3 88 0.01024897\n",
      "train:  3 89 0.0102346\n",
      "train:  3 90 0.009850913\n",
      "train:  3 91 0.010536242\n",
      "train:  3 92 0.008984291\n",
      "train:  3 93 0.008166691\n",
      "train:  3 94 0.008505752\n",
      "train:  3 95 0.009065423\n",
      "train:  3 96 0.010713471\n",
      "train:  3 97 0.0093423575\n",
      "train:  3 98 0.010084813\n",
      "train:  3 99 0.009050626\n",
      "train:  3 100 0.008833889\n",
      "evalu:  3 100 [0.00918381]\n",
      "train:  3 101 0.008058526\n",
      "train:  3 102 0.008826733\n",
      "train:  3 103 0.009443414\n",
      "train:  3 104 0.01012221\n",
      "train:  3 105 0.0068682902\n",
      "train:  3 106 0.0075843134\n",
      "train:  3 107 0.009673918\n",
      "train:  3 108 0.008810566\n",
      "train:  3 109 0.010223745\n",
      "train:  3 110 0.0077141104\n",
      "train:  3 111 0.008771916\n",
      "train:  3 112 0.008850554\n",
      "train:  3 113 0.009654673\n",
      "train:  3 114 0.0088532455\n",
      "train:  3 115 0.009116465\n",
      "train:  3 116 0.009194605\n",
      "train:  3 117 0.0099382\n",
      "train:  3 118 0.008358045\n",
      "train:  3 119 0.010351188\n",
      "train:  3 120 0.009537477\n",
      "evalu:  3 120 [0.008749735]\n",
      "train:  3 121 0.008741469\n",
      "train:  3 122 0.009486204\n",
      "train:  3 123 0.009617065\n",
      "train:  3 124 0.009201651\n",
      "train:  3 125 0.008674166\n",
      "train:  3 126 0.007816183\n",
      "train:  3 127 0.0074077984\n",
      "train:  3 128 0.009128769\n",
      "train:  3 129 0.0086914\n",
      "train:  3 130 0.0074949563\n",
      "train:  3 131 0.008613759\n",
      "train:  3 132 0.008435852\n",
      "train:  3 133 0.008740437\n",
      "train:  3 134 0.009044372\n",
      "train:  3 135 0.006985617\n",
      "train:  3 136 0.009529963\n",
      "train:  3 137 0.007573771\n",
      "train:  3 138 0.008683359\n",
      "train:  3 139 0.010030925\n",
      "train:  3 140 0.008804385\n",
      "evalu:  3 140 [0.008351437]\n",
      "train:  3 141 0.008407513\n",
      "train:  3 142 0.007954863\n",
      "train:  3 143 0.008565247\n",
      "train:  3 144 0.009179525\n",
      "train:  3 145 0.008257518\n",
      "train:  3 146 0.009756904\n",
      "train:  3 147 0.0077307406\n",
      "train:  3 148 0.007624074\n",
      "train:  3 149 0.008972096\n",
      "train:  3 150 0.0069072205\n",
      "train:  3 151 0.007838409\n",
      "train:  3 152 0.0085584\n",
      "train:  3 153 0.007335489\n",
      "train:  3 154 0.008425307\n",
      "train:  3 155 0.0088546155\n",
      "train:  3 156 0.008029988\n",
      "train:  3 157 0.008207103\n",
      "Running Test data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: m_72910/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batchsize=100\n",
    "#xbatch=dftrain2.loc[:,cols].head(10).values\n",
    "evalbatch=dfeval[cols]\n",
    "numepochs=4\n",
    "\n",
    "treerr=[]\n",
    "everr=[]\n",
    "modeldir=\"m_{:05d}\".format(np.random.randint(100000))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(numepochs):\n",
    "        for i in range(dftrain2.shape[0]//batchsize):\n",
    "            xbatch=dftrain2.iloc[i*batchsize:(i+1)*batchsize][cols]\n",
    "            _,ltr=sess.run([trainstep,loss],feed_dict={inputs:xbatch})\n",
    "            print(\"train: \",epoch,i,ltr)\n",
    "            if i%20==0:\n",
    "                l=sess.run([loss],feed_dict={inputs:evalbatch})\n",
    "                print(\"evalu: \",epoch,i,l)\n",
    "                treerr.append(ltr)\n",
    "                everr.append(l)\n",
    "     \n",
    "    print(\"Running Test data...\")\n",
    "    out=[]\n",
    "    for i in range(dftest.shape[0]):\n",
    "        testbatch=np.array([dftest.iloc[i][cols].values])\n",
    "        l=sess.run([loss,Yout],feed_dict={inputs:testbatch})\n",
    "        out.append([dftest.iloc[i]['Class'],l[0],l[1]])\n",
    "    tf.saved_model.simple_save(sess,modeldir, inputs=\n",
    "                           {\n",
    "                               \"inputs\":inputs#,'labels':labels,\"learnrate\":learnrate,\"droprate\":droprate,\"mode\":mode\n",
    "                           },\n",
    "                           outputs={\"Yout\":Yout,\"loss\":loss}#,\"batchloss\":batchloss}\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3ba20dd8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(treerr)\n",
    "plt.plot(everr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>err</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3288.0</td>\n",
       "      <td>3288.000000</td>\n",
       "      <td>3288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          err  predicted\n",
       "count  3288.0  3288.000000     3288.0\n",
       "mean      0.0     0.008406        0.0\n",
       "std       0.0     0.008021        0.0\n",
       "min       0.0     0.000664        0.0\n",
       "25%       0.0     0.003249        0.0\n",
       "50%       0.0     0.005915        0.0\n",
       "75%       0.0     0.010446        0.0\n",
       "max       0.0     0.081661        0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=np.array(out)\n",
    "dfout=pd.DataFrame(data={\"label\":out[:,0],\"err\":out[:,1],\"predicted\":out[:,2]})\n",
    "dfout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>err</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022838</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label       err  predicted\n",
       "0       0.0  0.026764        0.0\n",
       "1       0.0  0.002391        0.0\n",
       "2       0.0  0.004854        0.0\n",
       "3       0.0  0.001613        0.0\n",
       "4       0.0  0.024121        0.0\n",
       "5       0.0  0.003875        0.0\n",
       "6       0.0  0.003185        0.0\n",
       "7       0.0  0.005945        0.0\n",
       "8       0.0  0.000930        0.0\n",
       "9       0.0  0.002634        0.0\n",
       "10      0.0  0.006799        0.0\n",
       "11      0.0  0.011329        0.0\n",
       "12      0.0  0.010601        0.0\n",
       "13      0.0  0.015073        0.0\n",
       "14      0.0  0.002210        0.0\n",
       "15      0.0  0.010675        0.0\n",
       "16      0.0  0.009469        0.0\n",
       "17      0.0  0.002087        0.0\n",
       "18      0.0  0.002250        0.0\n",
       "19      0.0  0.017270        0.0\n",
       "20      0.0  0.002124        0.0\n",
       "21      0.0  0.022838        0.0\n",
       "22      0.0  0.011522        0.0\n",
       "23      0.0  0.004208        0.0\n",
       "24      0.0  0.002619        0.0\n",
       "25      0.0  0.001449        0.0\n",
       "26      0.0  0.007691        0.0\n",
       "27      0.0  0.010144        0.0\n",
       "28      0.0  0.001894        0.0\n",
       "29      0.0  0.005648        0.0\n",
       "...     ...       ...        ...\n",
       "3258    0.0  0.006592        0.0\n",
       "3259    0.0  0.002592        0.0\n",
       "3260    0.0  0.009024        0.0\n",
       "3261    0.0  0.001877        0.0\n",
       "3262    0.0  0.001000        0.0\n",
       "3263    0.0  0.009812        0.0\n",
       "3264    0.0  0.015452        0.0\n",
       "3265    0.0  0.008134        0.0\n",
       "3266    0.0  0.011887        0.0\n",
       "3267    0.0  0.003288        0.0\n",
       "3268    0.0  0.003977        0.0\n",
       "3269    0.0  0.003125        0.0\n",
       "3270    0.0  0.002719        0.0\n",
       "3271    0.0  0.004162        0.0\n",
       "3272    0.0  0.001693        0.0\n",
       "3273    0.0  0.002761        0.0\n",
       "3274    0.0  0.012107        0.0\n",
       "3275    0.0  0.003950        0.0\n",
       "3276    0.0  0.000777        0.0\n",
       "3277    0.0  0.002755        0.0\n",
       "3278    0.0  0.017210        0.0\n",
       "3279    0.0  0.031686        0.0\n",
       "3280    0.0  0.007548        0.0\n",
       "3281    0.0  0.010597        0.0\n",
       "3282    0.0  0.014252        0.0\n",
       "3283    0.0  0.008331        0.0\n",
       "3284    0.0  0.005112        0.0\n",
       "3285    0.0  0.023258        0.0\n",
       "3286    0.0  0.007653        0.0\n",
       "3287    0.0  0.005609        0.0\n",
       "\n",
       "[3288 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01642723413676222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.describe().loc['mean','err']+dfout.describe().loc['std','err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh2 of err = mean+std =  0.01642723413676222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015833903718913987"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh2=dfout.describe().loc['mean','err']+dfout.describe().loc['std','err']\n",
    "print(\"thresh2 of err = mean+std = \",thresh2)\n",
    "dfout['pred2']=0\n",
    "dfout.loc[dfout['err']>thresh2,'pred2']=1\n",
    "dfout.pred2.sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n"
     ]
    }
   ],
   "source": [
    "#Defining Prediction from loss\n",
    "print(thresh)\n",
    "dfout['pred']=0\n",
    "dfout.loc[dfout['err']>thresh,'pred']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>err</th>\n",
       "      <th>predicted</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3288.0</td>\n",
       "      <td>3288.000000</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>3288.000000</td>\n",
       "      <td>3288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          err  predicted        pred2    pred\n",
       "count  3288.0  3288.000000     3288.0  3288.000000  3288.0\n",
       "mean      0.0     0.008406        0.0     0.105535     0.0\n",
       "std       0.0     0.008021        0.0     0.307289     0.0\n",
       "min       0.0     0.000664        0.0     0.000000     0.0\n",
       "25%       0.0     0.003249        0.0     0.000000     0.0\n",
       "50%       0.0     0.005915        0.0     0.000000     0.0\n",
       "75%       0.0     0.010446        0.0     0.000000     0.0\n",
       "max       0.0     0.081661        0.0     1.000000     0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46061829, 0.8       , 0.34281054, 0.57682829, 0.69224514,\n",
       "        0.36265347, 0.74666667, 0.32222222, 0.84132227]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
